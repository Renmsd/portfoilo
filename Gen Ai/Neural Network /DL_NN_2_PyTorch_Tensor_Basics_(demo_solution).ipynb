{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renmsd/portfoilo/blob/main/Gen%20Ai/Neural%20Network%20/DL_NN_2_PyTorch_Tensor_Basics_(demo_solution).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10978eb0",
      "metadata": {
        "id": "10978eb0"
      },
      "source": [
        "<img src=\"https://s3.amazonaws.com/weclouddata/images/logos/wcd_logo_new_2.png\" width=\"10%\">\n",
        "<h1><center>Pytorch Basics</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d61c2f5",
      "metadata": {
        "id": "9d61c2f5"
      },
      "source": [
        "## Tensor Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4723f7a1",
      "metadata": {
        "id": "4723f7a1"
      },
      "source": [
        "### Tensor and dimension of tensor\n",
        "\n",
        "Tensor is thought of generalization of scalars, vectors, and matrices to higher dimensions.\n",
        "\n",
        "**0-D tensor**: A scalar (just a single number), for example: `1`\n",
        "\n",
        "**1-D tensor**: A vector (like a list of numbers), for example: `[1, 2, 3]`\n",
        "\n",
        "**2-D tensor**: A matrix (like a 2D grid of numbers), for example:\n",
        "```\n",
        "[\n",
        " [1,2,3],\n",
        " [4,5,6]\n",
        "]\n",
        "```\n",
        "\n",
        "**3-D tensor and higher**: Higher-dimensional arrays or tensors. Here is an exmaple for 3-D tensor:\n",
        "```\n",
        "[\n",
        " [\n",
        "  [1,2,3],\n",
        "  [4,5,6]\n",
        " ],\n",
        " [\n",
        "  [9,8,7],\n",
        "  [6,5,4]\n",
        " ]\n",
        "]\n",
        "```\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*pgVlfgFbk3t3FWe3QEVlXA.png\" alt=\"Markdown Monster icon\" width=\"30%\" />\n",
        "\n",
        "More visually:\n",
        "\n",
        "0-D tensor (Scalar) is like a single point.\n",
        "\n",
        "1-D tensor (Vector) is like a line with multiple points.\n",
        "\n",
        "2-D tensor (Matrix) is like a grid or a table. Imagine a spreadsheet or a checkerboard.\n",
        "\n",
        "3-D tensor is like a cube or box.\n",
        "\n",
        "4-D tensor is like a series of cubes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf0276c",
      "metadata": {
        "id": "2bf0276c"
      },
      "source": [
        "### Tensor Dimensions in NLP and Computer Vision Tasks\n",
        "\n",
        "Here are some sample use cases for multiple dimension tensor in NLP(Natural Language Processing) and CV(Computer Vision)\n",
        "\n",
        "<br />\n",
        "\n",
        "#### NLP\n",
        "**1. Word Embeddings**:\n",
        " - Single Word:\n",
        "   - 1-D tensor(vector): If you embed a single word using, for instance, a 300-dimensional embedding, you get a vector of size **`[embedding_dimension]`**.\n",
        "     - Example: \"cat\" → `[0.12, -0.25, ... , 0.45]` (assuming 300 elements in total)\n",
        " - Squence of words:\n",
        "   - 2-D tensors(matrix): If you have a sequence of words and represent each word by an embedding vector, the data can be represented as a matrix of size **`[sequence_length, embedding_dimension]`**.\n",
        "\n",
        "<br />\n",
        "\n",
        "**2. Batch of Sequences**:\n",
        "\n",
        " - 3-D tensors: When processing multiple sequences in a batch, it's common to have a tensor of shape **`[batch_size, sequence_length, embedding_dimension]`**.\n",
        "\n",
        " <br />\n",
        "\n",
        "**3. Recurrent Neural Networks (RNNs)**:\n",
        "\n",
        " - 3-D tensors: RNNs often operate on 3-D tensors where dimensions can represent **`[batch_size, sequence_length, features]`**.\n",
        "\n",
        " <br />\n",
        "\n",
        "**4. Transformer Architectures (like BERT)**:\n",
        "\n",
        " - 3-D tensors: Similar to RNNs, the input and intermediate representations are often 3-D tensors, e.g., **`[batch_size, sequence_length, embedding_dimension]`**.\n",
        "\n",
        " <br />\n",
        "\n",
        "**5. One-Hot Encoded Text**:\n",
        "\n",
        " - One-hot encoding represents words (or characters) as vectors where all positions are zero, except for the position corresponding to the word, which is set to 1.\n",
        "\n",
        " - Single Word:\n",
        "   - Vector (1-D tensor): For a vocabulary of size `V`, a word's one-hot representation would be a vector of size `[V]`, with one element set to 1, and all others set to 0.\n",
        "     - Example: For a vocabulary `{\"the\", \"black\", \"cat\"}`, the word \"cat\" might be represented as `[0, 0, 1]`.\n",
        " - Sequence of Words:\n",
        "   - Matrix (2-D tensor): For a sequence of n words, you'd stack the one-hot vectors, leading to a size of **`[sequence_length, V]`**.\n",
        "     - Example: \"The black cat\" → matrix of size `(3, 3)`, with each row being the one-hot representation of a word.\n",
        "     \n",
        "<br />\n",
        "\n",
        "**6. Document Embeddings**:\n",
        " - Single Document:\n",
        "   - Vector (1-D tensor): A document embedded into a fixed-size vector, e.g., 500-dimensional, would have size `[embedding_dimension]`.\n",
        "     - Example: The entire text of \"The quick brown fox jumps over the lazy dog\" is transformed into a vector like `[0.45, -0.12, ... , 0.58]` (assuming 500 elements).\n",
        " - Batch of Documents:\n",
        "   - Matrix (2-D tensor): For a batch of `m` documents, where each document is represented as a fixed-size vector (e.g., 500-dimensional), you'd have a matrix of size **`[batch_size, embedding_dimension]`**.\n",
        "     - Example: If you're processing 10 documents at once, each with a 500-dimensional embedding, the tensor shape would be `(10, 500)`.\n",
        "     \n",
        "<br />\n",
        "\n",
        "#### CV\n",
        "**1. Images**:\n",
        " - 3-D tensors: Common for individual images. Dimensions usually represent **`[height, width, channels]`** where channels are often RGB (3 channels). For grayscale images, the dimension might be just **`[height, width, 1]`**.\n",
        " - In Pytorch, the shape is `[channels, height, width]`\n",
        "\n",
        "<br />\n",
        "\n",
        "**2.Batches of Images**:\n",
        " - 4-D tensors: When processing multiple images in a batch, another dimension is added. For example, **`[batch_size, height, width, channels]`**.\n",
        " - In Pytorch, the shape is `[batch_size, channels, height, width]`\n",
        "\n",
        "<br />\n",
        "\n",
        "**3.Convolutional Neural Networks**:\n",
        "- 4-D tensors: Convolutional layers in deep learning models often operate on 4-D tensors, especially when using mini-batch training. Intermediate layers can produce tensors of varying spatial dimensions depending on the layer's operations (e.g., convolution, pooling)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae456b64",
      "metadata": {
        "id": "ae456b64"
      },
      "source": [
        "### Create Tensor in Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37da6a9",
      "metadata": {
        "id": "b37da6a9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c1ce78",
      "metadata": {
        "id": "b1c1ce78"
      },
      "source": [
        "#### Create from Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a1a889",
      "metadata": {
        "id": "30a1a889"
      },
      "outputs": [],
      "source": [
        "# create a numpy array\n",
        "arr = np.array([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62386fe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62386fe3",
        "outputId": "8910063d-bc8d-4f87-e867-c82168fdee58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# check the data type and arr type\n",
        "arr.dtype, type(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1276ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1276ad",
        "outputId": "e17cd8fa-1cae-4cc6-bbce-ee72a55ac59a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# convert numpy array to tensor\n",
        "my_tensor = torch.from_numpy(arr)\n",
        "\n",
        "my_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243be2ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243be2ca",
        "outputId": "8e7ceb9c-95e1-4812-afb7-7402007317bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(my_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408809cf",
      "metadata": {
        "id": "408809cf"
      },
      "outputs": [],
      "source": [
        "# convert 2d array to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf216da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbf216da",
        "outputId": "db806ab1-b76f-40be-936f-dfe33aa3b057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "arr2d = np.arange(0.0, 9.0)\n",
        "arr2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9efd51a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9efd51a",
        "outputId": "3b21c1d2-3e98-4fc5-8ce6-dcda9c53587e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 2.],\n",
              "       [3., 4., 5.],\n",
              "       [6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "arr2d = arr2d.reshape(3, 3)\n",
        "arr2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2a5a99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2a5a99",
        "outputId": "d8ae8e3a-0c66-43ab-8210-0474907e9a45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 4., 5.],\n",
              "        [6., 7., 8.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "my_2dtensor =  torch.from_numpy(arr2d)\n",
        "my_2dtensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b3189b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90b3189b",
        "outputId": "34b6f569-0d47-4dff-c927-6c72d663a2b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# another way to convert the numpy array to tensor\n",
        "my_tensor2 = torch.as_tensor(arr)\n",
        "\n",
        "my_tensor2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bccf48a",
      "metadata": {
        "id": "0bccf48a"
      },
      "source": [
        "The different between `torch.from_numpy` and `torch.as_tensor` is that:\n",
        " - Data Type Support\n",
        "   - `torch.from_numpy` only accepts numpy arrays.\n",
        "   - `torch.as_tensor` is more versatile. It can accept a wider range of data types, including numpy arrays, Python lists, scalar values, and other tensor-like objects.\n",
        " -  Dtype and Device Handling\n",
        "    - `torch.from_numpy` does not allow you to specify the dtype or device; the returned tensor's properties are inferred from the numpy array.\n",
        "    - `torch.as_tensor` provides more flexibility. You can use the dtype and device arguments to specify the desired data type and device (e.g., CPU or GPU) for the created tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e67b853",
      "metadata": {
        "id": "5e67b853"
      },
      "outputs": [],
      "source": [
        "# The code below will give you the TypeError: expected np.ndarray (got list)\n",
        "# torch.from_numpy([1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162d9f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "162d9f69",
        "outputId": "701743fa-fd37-4be6-e8c9-02281518df4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# But it works with torch.as_tensor, since it support more data types\n",
        "torch.as_tensor([1, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b57f03c",
      "metadata": {
        "id": "7b57f03c"
      },
      "source": [
        "from the document of `torch.from_numpy`, we can see it only take one parameter, which is `ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38895a4",
      "metadata": {
        "scrolled": true,
        "id": "f38895a4",
        "outputId": "4e62aae1-7e6d-4a3f-86ed-cd1b8717dce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function from_numpy in module torch:\n",
            "\n",
            "from_numpy(...)\n",
            "    from_numpy(ndarray) -> Tensor\n",
            "\n",
            "    Creates a :class:`Tensor` from a :class:`numpy.ndarray`.\n",
            "\n",
            "    The returned tensor and :attr:`ndarray` share the same memory. Modifications to\n",
            "    the tensor will be reflected in the :attr:`ndarray` and vice versa. The returned\n",
            "    tensor is not resizable.\n",
            "\n",
            "    It currently accepts :attr:`ndarray` with dtypes of ``numpy.float64``,\n",
            "    ``numpy.float32``, ``numpy.float16``, ``numpy.complex64``, ``numpy.complex128``,\n",
            "    ``numpy.int64``, ``numpy.int32``, ``numpy.int16``, ``numpy.int8``, ``numpy.uint8``,\n",
            "    and ``bool``.\n",
            "\n",
            "    .. warning::\n",
            "        Writing to a tensor created from a read-only NumPy array is not supported and will result in undefined behavior.\n",
            "\n",
            "    Example::\n",
            "\n",
            "        >>> a = numpy.array([1, 2, 3])\n",
            "        >>> t = torch.from_numpy(a)\n",
            "        >>> t\n",
            "        tensor([ 1,  2,  3])\n",
            "        >>> t[0] = -1\n",
            "        >>> a\n",
            "        array([-1,  2,  3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(torch.from_numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d70977b",
      "metadata": {
        "id": "0d70977b"
      },
      "source": [
        "But in the document of `torch.as_tensor`, it also takes dtype and device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfea3523",
      "metadata": {
        "scrolled": true,
        "id": "bfea3523",
        "outputId": "86dc84b8-3c51-44ee-8dba-82ff37ac23a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function as_tensor in module torch:\n",
            "\n",
            "as_tensor(...)\n",
            "    as_tensor(data: Any, dtype: Optional[dtype] = None, device: Optional[DeviceLikeType]) -> Tensor\n",
            "\n",
            "    Converts :attr:`data` into a tensor, sharing data and preserving autograd\n",
            "    history if possible.\n",
            "\n",
            "    If :attr:`data` is already a tensor with the requested dtype and device\n",
            "    then :attr:`data` itself is returned, but if :attr:`data` is a\n",
            "    tensor with a different dtype or device then it's copied as if using\n",
            "    `data.to(dtype=dtype, device=device)`.\n",
            "\n",
            "    If :attr:`data` is a NumPy array (an ndarray) with the same dtype and device then a\n",
            "    tensor is constructed using :func:`torch.from_numpy`.\n",
            "\n",
            "    If :attr:`data` is a CuPy array, the returned tensor will be located on the same device as the CuPy array unless\n",
            "    specifically overwritten by :attr:`device` or a default device.\n",
            "\n",
            "    .. seealso::\n",
            "\n",
            "        :func:`torch.tensor` never shares its data and creates a new \"leaf tensor\" (see :doc:`/notes/autograd`).\n",
            "\n",
            "\n",
            "    Args:\n",
            "        data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
            "            NumPy ``ndarray``, scalar, and other types.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, infers data type from :attr:`data`.\n",
            "        device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor\n",
            "            then the device of data is used. If None and data is not a tensor then\n",
            "            the result tensor is constructed on the current device.\n",
            "\n",
            "\n",
            "    Example::\n",
            "\n",
            "        >>> a = numpy.array([1, 2, 3])\n",
            "        >>> t = torch.as_tensor(a)\n",
            "        >>> t\n",
            "        tensor([ 1,  2,  3])\n",
            "        >>> t[0] = -1\n",
            "        >>> a\n",
            "        array([-1,  2,  3])\n",
            "\n",
            "        >>> a = numpy.array([1, 2, 3])\n",
            "        >>> t = torch.as_tensor(a, device=torch.device('cuda'))\n",
            "        >>> t\n",
            "        tensor([ 1,  2,  3])\n",
            "        >>> t[0] = -1\n",
            "        >>> a\n",
            "        array([1,  2,  3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(torch.as_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f75b3246",
      "metadata": {
        "id": "f75b3246",
        "outputId": "bbd25570-ae1b-44d7-f8bb-122fd39725c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "arr.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbcaade",
      "metadata": {
        "id": "3cbcaade",
        "outputId": "e12cb8ae-d2ea-4d96-b949-fee919a2fa23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4]), tensor([1, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# my_tensor2 are the tensor directly convert from the numpy arrau in our previous code\n",
        "my_tensor, my_tensor2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91653f61",
      "metadata": {
        "id": "91653f61",
        "outputId": "68d5b84f-9c2c-4862-9b92-df659cdde6b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "torch.int64\n",
            "tensor([1., 2., 3., 4.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "my_tensor3 = torch.as_tensor(arr, dtype=torch.int64)\n",
        "my_tensor4 = torch.as_tensor(arr, dtype=torch.float64)\n",
        "print(my_tensor3)\n",
        "print(my_tensor3.dtype)\n",
        "print(my_tensor4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e105fbc6",
      "metadata": {
        "id": "e105fbc6"
      },
      "outputs": [],
      "source": [
        "# use gpu with torch.as_tensor\n",
        "if torch.cuda.is_available():\n",
        "    torch.as_tensor(arr, dtype=torch.int64, device=torch.device('cuda:0'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2eaff8",
      "metadata": {
        "id": "af2eaff8"
      },
      "source": [
        "Both `torch.from_numpy` and `torch.as_tensor` share the same memory as numpy array, which means that it just creates a link to the numpy array, and if the value changes in the array, the value of the tensor will change as well, verse versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81ba58f",
      "metadata": {
        "id": "d81ba58f",
        "outputId": "02d809a5-e78e-43ca-ccec-1f380cfc6e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [1 2 3 4]\n",
            "tensor created by torch.from_numpy:\t tensor([1, 2, 3, 4])\n",
            "tensor created by torch.as_tensor:\t tensor([1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# my_tensor is created by torch.from_numpy from arr\n",
        "# my_tensor2 is create by torch.as_tensor from arr\n",
        "print(\"original numpy array\\t\\t\\t\", arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", my_tensor)\n",
        "print(\"tensor created by torch.as_tensor:\\t\", my_tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea19a6ca",
      "metadata": {
        "id": "ea19a6ca",
        "outputId": "b31f3c5d-9a15-4923-9fe0-7ed942170818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [100   2   3   4]\n",
            "tensor created by torch.from_numpy:\t tensor([100,   2,   3,   4])\n",
            "tensor created by torch.as_tensor:\t tensor([100,   2,   3,   4])\n"
          ]
        }
      ],
      "source": [
        "arr[0] = 100\n",
        "print(\"original numpy array\\t\\t\\t\", arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", my_tensor)\n",
        "print(\"tensor created by torch.as_tensor:\\t\", my_tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2f5fa2",
      "metadata": {
        "id": "2b2f5fa2",
        "outputId": "21d88dfb-54fa-4c5f-9daf-f8c6912ea30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [100  88   3   4]\n",
            "tensor created by torch.from_numpy:\t tensor([100,  88,   3,   4])\n",
            "tensor created by torch.as_tensor:\t tensor([100,  88,   3,   4])\n"
          ]
        }
      ],
      "source": [
        "my_tensor[1] = 88\n",
        "print(\"original numpy array\\t\\t\\t\", arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", my_tensor)\n",
        "print(\"tensor created by torch.as_tensor:\\t\", my_tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50b94ba",
      "metadata": {
        "id": "a50b94ba",
        "outputId": "039c0461-b665-469a-bc7c-9ad58ad95fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [100  88   3  66]\n",
            "tensor created by torch.from_numpy:\t tensor([100,  88,   3,  66])\n",
            "tensor created by torch.as_tensor:\t tensor([100,  88,   3,  66])\n"
          ]
        }
      ],
      "source": [
        "my_tensor2[3] = 66\n",
        "print(\"original numpy array\\t\\t\\t\", arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", my_tensor)\n",
        "print(\"tensor created by torch.as_tensor:\\t\", my_tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a75227",
      "metadata": {
        "id": "b6a75227"
      },
      "source": [
        "However, `torch.as_tensor` ***only*** share the memory when the input is numpy array. If it takes other data types as input, it won't share the memory.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d668a0",
      "metadata": {
        "id": "91d668a0",
        "outputId": "9254cece-3bc9-4f42-89f9-30979e3c98bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original list\t\t\t\t\t [1, 2, 3]\n",
            "tensor created by torch.as_tensor from list:\t tensor([1, 2, 3])\n",
            "After change the list\n",
            "original list\t\t\t\t\t [99, 2, 3]\n",
            "tensor created by torch.as_tensor from list:\t tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "my_ls = [1,2,3]\n",
        "my_tensor_from_ls = torch.as_tensor(my_ls)\n",
        "print(\"original list\\t\\t\\t\\t\\t\", my_ls)\n",
        "print(\"tensor created by torch.as_tensor from list:\\t\", my_tensor_from_ls)\n",
        "\n",
        "my_ls[0] = 99\n",
        "print(\"After change the list\")\n",
        "print(\"original list\\t\\t\\t\\t\\t\", my_ls)\n",
        "print(\"tensor created by torch.as_tensor from list:\\t\", my_tensor_from_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b92be9",
      "metadata": {
        "id": "53b92be9",
        "outputId": "4780a87c-6fc6-43f4-e332-a1a5ae64c29a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original value\t\t\t\t\t\t 10\n",
            "tensor created by torch.as_tensor from scalar value:\t tensor(10)\n",
            "After change the value\n",
            "original value\t\t\t\t\t\t 99\n",
            "tensor created by torch.as_tensor from scalar value:\t tensor(10)\n"
          ]
        }
      ],
      "source": [
        "my_val = 10\n",
        "my_tensor_from_val = torch.as_tensor(my_val)\n",
        "print(\"original value\\t\\t\\t\\t\\t\\t\", my_val)\n",
        "print(\"tensor created by torch.as_tensor from scalar value:\\t\", my_tensor_from_val)\n",
        "\n",
        "my_val = 99\n",
        "print(\"After change the value\")\n",
        "print(\"original value\\t\\t\\t\\t\\t\\t\", my_val)\n",
        "print(\"tensor created by torch.as_tensor from scalar value:\\t\", my_tensor_from_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f43f6297",
      "metadata": {
        "id": "f43f6297"
      },
      "source": [
        "If we **don't** want them to create the direct link and share the memory with numpy array, we just need a copy of the data, we can use `torch.tensor` or `torch.Tensor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abf44a5",
      "metadata": {
        "id": "5abf44a5",
        "outputId": "6b3df5b1-7730-4ddd-f48f-5f8905c1f429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [9 8 7 6 5]\n",
            "tensor created by torch.from_numpy:\t tensor([9, 8, 7, 6, 5])\n",
            "tensor created by torch.tensor:\t\t tensor([9, 8, 7, 6, 5])\n",
            "tensor created by torch.Tensor:\t\t tensor([9., 8., 7., 6., 5.])\n"
          ]
        }
      ],
      "source": [
        "# create a new array\n",
        "new_arr = np.array([9, 8, 7, 6, 5])\n",
        "\n",
        "# create tensor using torch.tensor\n",
        "new_tensor = torch.tensor(new_arr)\n",
        "\n",
        "# create tensor using torch.Tensor\n",
        "new_Tensor = torch.Tensor(new_arr)\n",
        "\n",
        "# create tensor using torch.from_numpy\n",
        "new_tensor_from_np = torch.from_numpy(new_arr)\n",
        "\n",
        "print(\"original numpy array\\t\\t\\t\", new_arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", new_tensor_from_np)\n",
        "print(\"tensor created by torch.tensor:\\t\\t\", new_tensor)\n",
        "print(\"tensor created by torch.Tensor:\\t\\t\", new_Tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138b39bf",
      "metadata": {
        "id": "138b39bf",
        "outputId": "0e80b556-89b5-4786-ecbd-f2219eb5a57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [100   8   7   6   5]\n",
            "tensor created by torch.from_numpy:\t tensor([100,   8,   7,   6,   5])\n",
            "tensor created by torch.tensor:\t\t tensor([9, 8, 7, 6, 5])\n",
            "tensor created by torch.Tensor:\t\t tensor([9., 8., 7., 6., 5.])\n"
          ]
        }
      ],
      "source": [
        "new_arr[0] = 100\n",
        "print(\"original numpy array\\t\\t\\t\", new_arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", new_tensor_from_np)\n",
        "print(\"tensor created by torch.tensor:\\t\\t\", new_tensor)\n",
        "print(\"tensor created by torch.Tensor:\\t\\t\", new_Tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "784e21cd",
      "metadata": {
        "id": "784e21cd",
        "outputId": "ca0a259f-e887-46db-b048-7e9ccd298ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original numpy array\t\t\t [100   8   7  45   5]\n",
            "tensor created by torch.from_numpy:\t tensor([100,   8,   7,  45,   5])\n",
            "tensor created by torch.tensor:\t\t tensor([9, 8, 7, 6, 5])\n",
            "tensor created by torch.Tensor:\t\t tensor([9., 8., 7., 6., 5.])\n"
          ]
        }
      ],
      "source": [
        "new_arr[3] = 45\n",
        "print(\"original numpy array\\t\\t\\t\", new_arr)\n",
        "print(\"tensor created by torch.from_numpy:\\t\", new_tensor_from_np)\n",
        "print(\"tensor created by torch.tensor:\\t\\t\", new_tensor)\n",
        "print(\"tensor created by torch.Tensor:\\t\\t\", new_Tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbde04c1",
      "metadata": {
        "id": "dbde04c1"
      },
      "source": [
        "So there are no memory sharing between the original numpy array and the tensor created by the `torch.tensor`.\n",
        "\n",
        "The difference between `torch.tensor` and `torch.Tensor` is that, `torch.Tensor` is actually an alias for the default tensor type in PyTorch, which is `torch.FloatTensor`, which mean the dtype of tensor create by `torch.Tensor` is always `torch.float32`. But with `torch.tensor`, we can still assign the dtype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cee3337",
      "metadata": {
        "id": "8cee3337",
        "outputId": "b764449f-3245-4b9a-a67a-63529941224c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "print(new_Tensor.dtype)\n",
        "print(new_tensor.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "555dfcb9",
      "metadata": {
        "id": "555dfcb9",
        "outputId": "bda93a94-7194-468b-87c4-c75425c2943a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "new_tensor2 = torch.tensor(new_arr, dtype=torch.int64)\n",
        "print(new_tensor2.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c8bc97",
      "metadata": {
        "id": "a8c8bc97"
      },
      "source": [
        "In summary, these are the methods we can use to create the tensor from the numpy array:\n",
        "\n",
        "<br />\n",
        "\n",
        "| Method          | Acceptable Inputs              | Assignable `dtype` | Memory Sharing with numpy | Default `dtype` (if not assigned) |\n",
        "|-----------------|-------------------------------|--------------------|---------------------------|----------------------------------|\n",
        "| `torch.from_numpy` | Numpy arrays only            | No                 | Yes                       | Inferred from numpy array        |\n",
        "| `torch.as_tensor`  | Numpy arrays, lists, etc.    | Yes                | Yes (only with numpy & no dtype conversion) | Inferred from input            |\n",
        "| `torch.tensor`     | Numpy arrays, lists, etc.    | Yes                | No                        | Inferred from input              |\n",
        "| `torch.Tensor`     | Numpy arrays, lists, etc.    | No                 | No                        | `torch.float32`                  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d511859",
      "metadata": {
        "id": "8d511859"
      },
      "source": [
        "#### Create Directly\n",
        "\n",
        "Instead of convert numpy array to tensor, we can also create tendsor from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e340012",
      "metadata": {
        "id": "8e340012"
      },
      "source": [
        "`torch.empty` is used to allocate uninitialized memory for a tensor. The values that occupy the uninitialized memory can be arbitrary and should not be relied upon without first setting or initializing them in some manner. We can regard this as a placeholder for the memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c13aaab",
      "metadata": {
        "id": "3c13aaab",
        "outputId": "0f7d6bc5-ffed-4d49-d4fe-6292e34c0da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.8110e-09,  4.4256e-41],\n",
              "        [-9.8110e-09,  4.4256e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "torch.empty(2,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "506d458f",
      "metadata": {
        "id": "506d458f"
      },
      "source": [
        "Using the values from torch.empty without initialization can lead to unexpected behaviors, as the values are arbitrary.\n",
        "\n",
        "If we want to create a tensor with specific initial values (like zeros or ones), you would use functions like `torch.zeros` or `torch.ones` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a520570e",
      "metadata": {
        "id": "a520570e",
        "outputId": "81572188-1742-4fd6-d2d6-b82d23b6b180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.zeros(2,2))\n",
        "print(torch.zeros(3,4,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6ca225",
      "metadata": {
        "id": "ad6ca225",
        "outputId": "00bdedd8-e792-4363-cac3-8aa4e1bfd40d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.ones(2,2))\n",
        "print(torch.ones(3,4,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68316ede",
      "metadata": {
        "id": "68316ede"
      },
      "source": [
        "We can also use the function like `torch.arange` to create a range of vector, similary to the numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351b97af",
      "metadata": {
        "id": "351b97af",
        "outputId": "8311837d-02eb-4b67-dfe9-33cb885cb02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "np.arange(0, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba82068",
      "metadata": {
        "id": "8ba82068",
        "outputId": "d420bcc4-0efe-4d0b-d70b-a34397ee412c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "             #start, #end,  #step\n",
        "torch.arange(0,     10,     1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de15bb88",
      "metadata": {
        "id": "de15bb88",
        "outputId": "08c14af1-d84e-447c-c44b-2bdf17a22a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "torch.arange(0, 20, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3348c9df",
      "metadata": {
        "id": "3348c9df"
      },
      "source": [
        "And we can use reshape to reshape the above 1D tensor, similary to the numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e349a4",
      "metadata": {
        "id": "d1e349a4",
        "outputId": "1fa31e54-3b3f-4444-84eb-1b87ec8e0fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3],\n",
              "       [ 4,  5,  6,  7],\n",
              "       [ 8,  9, 10, 11],\n",
              "       [12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "np.arange(0, 16).reshape(4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58357c9",
      "metadata": {
        "id": "a58357c9",
        "outputId": "1d402d16-f043-409c-ad9b-76a3411b37f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "torch.arange(0, 12, 1).reshape(3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152e6776",
      "metadata": {
        "id": "152e6776"
      },
      "source": [
        "Or we can also use the `linspace`, which returns a 1-dimensional tensor of evenly spaced values between two specified start and end values. Similar to the numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adff2f4b",
      "metadata": {
        "id": "adff2f4b",
        "outputId": "0bf4b5f0-dc1d-42d5-d3e6-1383163e3b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  2.,  4.,  6.,  8., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "np.linspace(0, 10, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147ac11a",
      "metadata": {
        "id": "147ac11a",
        "outputId": "ef32ab4e-49b4-42f9-ba64-ad1bf33eaee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  2.,  4.,  6.,  8., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "torch.linspace(0, 10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29158d2d",
      "metadata": {
        "id": "29158d2d"
      },
      "source": [
        "We can use `torch.rand`, `torch.randn` and `torch.randint` to generate tensor with random value.\n",
        "\n",
        "`torch.rand`: Generates a tensor filled with random numbers uniformly distributed between `0` and `1`.\n",
        "\n",
        "`torch.randn`: Generates a tensor filled with random numbers from a standard normal distribution (mean = 0 and variance = 1).\n",
        "\n",
        "`torch.randint`:  a tensor filled with random integers between `low`(inclusive) and `high`(exclusive). If only one value is provided, it assumes between 0 and that value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e470541",
      "metadata": {
        "id": "1e470541",
        "outputId": "6474486f-115c-4a39-8ffd-f65295f1f109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5440, 0.1149],\n",
              "        [0.3675, 0.7683]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "torch.rand(2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df2b6f4",
      "metadata": {
        "id": "8df2b6f4",
        "outputId": "7b102e76-e965-47ba-8de4-06dd5514246c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0583, -1.5705],\n",
              "        [ 2.1867, -1.8893]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "torch.randn(2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c829df0",
      "metadata": {
        "id": "5c829df0",
        "outputId": "f6858180-b91b-485f-9e38-988a86a6a755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6, 8],\n",
              "        [8, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "              #low  #high   #size\n",
        "torch.randint(0,    10,    (2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8b1f53",
      "metadata": {
        "id": "df8b1f53"
      },
      "source": [
        "Since we are generating the random value here, similar to `numpy.random.seed()` method, PyTorch also have a method called `torch.manual_seed()`, which is used to set the random seed for generating deterministic random numbers, ensuring reproducibility across runs.\n",
        "\n",
        "Reproducibility is crucial in many areas, especially in scientific experiments, machine learning, and data analysis. By using a consistent seed value for random number generation, researchers and practitioners can ensure that the randomness introduced in their experiments is consistent every time they run them. This makes experiments replicable and results comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff72a8bb",
      "metadata": {
        "id": "ff72a8bb",
        "outputId": "e3e55da7-a721-4d76-da00-3817e9a7cc99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8823, 0.9150, 0.3829, 0.9593, 0.3904])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.rand(5)\n",
        "print(x)  # This will produce the same values every time you run it with the seed set to 42."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dcb6141",
      "metadata": {
        "id": "4dcb6141"
      },
      "source": [
        "Please note that, for reproducibility in interactive environments like Jupyter Notebooks, it's advisable to set the random seed using `torch.manual_seed()` and immediately generate random numbers **within the same cell**. This practice ensures consistent results every time the cell is executed, guarding against potential inconsistencies that might arise from executing cells out of order or intervening operations that use the random number generator."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771f39e4",
      "metadata": {
        "id": "771f39e4"
      },
      "source": [
        "Until now, we can see for PyTorch, most of the methods to generate value are similar to numpy, so if you are familiar with numpy, you can get on this easily."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b42b030",
      "metadata": {
        "id": "7b42b030"
      },
      "source": [
        "In PyTorch, we can also use the `*_like` methods to create tensors with the **same shape**(and, optionally, data type) as a given tensor. These methods are convenient when you want a new tensor that matches the dimensions of an existing tensor but initialized differently.\n",
        "\n",
        "Here are the examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34c7e22b",
      "metadata": {
        "id": "34c7e22b"
      },
      "outputs": [],
      "source": [
        "# give an example of 3D tensor\n",
        "my_3dtensor = torch.tensor([\n",
        "    [\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6]\n",
        "    ],\n",
        "    [\n",
        "        [9, 8, 7],\n",
        "        [6, 5, 4]\n",
        "    ]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b41e6de",
      "metadata": {
        "id": "2b41e6de",
        "outputId": "058213b3-d227-4f59-a6e0-dd08e75b8686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "my_3dtensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73af7c9a",
      "metadata": {
        "id": "73af7c9a",
        "outputId": "588cfff8-7fc9-44cf-fea0-86ffdd946688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "my_3dtensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5b6ba5",
      "metadata": {
        "scrolled": true,
        "id": "2d5b6ba5",
        "outputId": "0e8ee0d9-2d13-4724-df02-de43e03ed4e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.empty_like\n",
            "tensor([[[                  0, 7310593858020254331, 3616445622929465956],\n",
            "         [6067810143254359349, 3473746704966760496, 6501281654583275822]],\n",
            "\n",
            "        [[7309453675965983778, 8315168162784306286, 8367752027310484831],\n",
            "         [7954801838398993778, 2459029315949324647, 7220452424185754672]]])\n",
            "================================================================================\n",
            "torch.zeros_like\n",
            "tensor([[[0, 0, 0],\n",
            "         [0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0],\n",
            "         [0, 0, 0]]])\n",
            "================================================================================\n",
            "torch.ones_like\n",
            "tensor([[[1, 1, 1],\n",
            "         [1, 1, 1]],\n",
            "\n",
            "        [[1, 1, 1],\n",
            "         [1, 1, 1]]])\n",
            "================================================================================\n",
            "torch.randint_like\n",
            "tensor([[[5, 0, 4],\n",
            "         [0, 3, 8]],\n",
            "\n",
            "        [[4, 0, 4],\n",
            "         [1, 2, 5]]])\n"
          ]
        }
      ],
      "source": [
        "print(\"torch.empty_like\")\n",
        "print(torch.empty_like(my_3dtensor))\n",
        "print(\"=\"*80)\n",
        "print(\"torch.zeros_like\")\n",
        "print(torch.zeros_like(my_3dtensor))\n",
        "print(\"=\"*80)\n",
        "print(\"torch.ones_like\")\n",
        "print(torch.ones_like(my_3dtensor))\n",
        "print(\"=\"*80)\n",
        "print(\"torch.randint_like\")\n",
        "print(torch.randint_like(my_3dtensor, low=0, high=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c4734c",
      "metadata": {
        "id": "68c4734c"
      },
      "source": [
        "BUT note that if we run `torch.rand_like` and `torch.randn_like` on this example, we will get the data type issue. The function `torch.rand_like()` tries to fill a tensor with random numbers from a uniform distribution in the range `[0, 1)` and `torch.randn_like()` tries to fill with random numbers drawn from a standard normal distribution (with mean 0 and standard deviation 1). This operation requires a **floating-point data type**, but our `my_3dtensor` is **`int64`**.\n",
        "\n",
        "To avoid the error, we can convert the `my_3dtensor` to a floating-point type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85fdca9",
      "metadata": {
        "scrolled": true,
        "id": "c85fdca9",
        "outputId": "f5f9ad60-85e9-4886-a1c0-fc6a72621276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.rand_like\n",
            "tensor([[[0.5739, 0.2666, 0.6274],\n",
            "         [0.2696, 0.4414, 0.2969]],\n",
            "\n",
            "        [[0.8317, 0.1053, 0.2695],\n",
            "         [0.3588, 0.1994, 0.5472]]])\n",
            "================================================================================\n",
            "torch.randn_like\n",
            "tensor([[[ 1.2931,  0.4137, -0.5710],\n",
            "         [-0.9749,  0.1863,  1.6273]],\n",
            "\n",
            "        [[ 1.1214, -0.6605, -0.0131],\n",
            "         [ 1.5860, -1.0186, -0.4180]]])\n"
          ]
        }
      ],
      "source": [
        "# convert to float-point type\n",
        "my_3dtensor_float = my_3dtensor.to(torch.float32)\n",
        "\n",
        "print(\"torch.rand_like\")\n",
        "print(torch.rand_like(my_3dtensor_float))\n",
        "print(\"=\"*80)\n",
        "print(\"torch.randn_like\")\n",
        "print(torch.randn_like(my_3dtensor_float))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3bed56",
      "metadata": {
        "id": "ce3bed56"
      },
      "source": [
        "However, `torch.randint_like` doesn't have restrictions on the source dtype, it will produce a tensor with the same data type as the source tensor, even if the generated values are integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc5b8a7",
      "metadata": {
        "id": "bcc5b8a7",
        "outputId": "081e952c-0745-4246-f723-34c0d300740a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2935,  1.4329],\n",
            "        [ 0.5312, -0.2483]])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "my_float_tensor = torch.randn(2,2)\n",
        "print(my_float_tensor)\n",
        "print(my_float_tensor.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca0ee19",
      "metadata": {
        "id": "dca0ee19",
        "outputId": "665992e7-ec19-4196-b940-36fb2ee18157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "my_generate_tensor = torch.randint_like(my_float_tensor, low=0, high=10)\n",
        "my_generate_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edc917ba",
      "metadata": {
        "id": "edc917ba",
        "outputId": "f50f1f39-4688-4338-b4fa-0196ab49755b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "my_generate_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6fcf021",
      "metadata": {
        "id": "d6fcf021"
      },
      "source": [
        "Here is the summary of the `*_like` methods:\n",
        "\n",
        "<br />\n",
        "\n",
        "| Method                      | Description                                                           | Requires Source `dtype`   | Output `dtype`                  |\n",
        "|-----------------------------|-----------------------------------------------------------------------|---------------------------|--------------------------------|\n",
        "| `torch.empty_like(tensor)`  | Generates an uninitialized tensor.                                    | Any                       | Matches source tensor          |\n",
        "| `torch.zeros_like(tensor)`  | Generates a tensor filled with zeros.                                 | Any                       | Matches source tensor          |\n",
        "| `torch.ones_like(tensor)`   | Generates a tensor filled with ones.                                  | Any                       | Matches source tensor          |\n",
        "| `torch.rand_like(tensor)`   | Generates uniform random numbers between 0 and 1.                     | Floating-point            | Matches source tensor          |\n",
        "| `torch.randn_like(tensor)`  | Generates random numbers from a standard normal distribution.         | Floating-point            | Matches source tensor          |\n",
        "| `torch.randint_like(tensor, low, high)` | Generates random integers between `low` and `high` (exclusive). | Any                       | Matches source tensor, but filled with integers |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d83cab",
      "metadata": {
        "id": "83d83cab"
      },
      "source": [
        "There are another two methods you may need to use to create the tensor:\n",
        "\n",
        "`torch.full` - It creates a tensor of size size with all values set to fill_value.\n",
        "\n",
        "`torch.eye` - It creates a 2-D tensor with ones on the diagonal and zeros elsewhere, essentially an identity matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ada50a2",
      "metadata": {
        "id": "4ada50a2",
        "outputId": "408b22af-98dc-40f2-d5ae-d2f8502c42a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7, 7, 7],\n",
              "        [7, 7, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "torch.full((2, 3), 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1f771d",
      "metadata": {
        "id": "ce1f771d",
        "outputId": "62532e1f-bbaa-4c2d-9488-3aa26a88c9d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "torch.eye(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e25807",
      "metadata": {
        "id": "85e25807"
      },
      "source": [
        "In additional, all the `torch.*` method we metioned here supports the GPU computation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0866638e",
      "metadata": {
        "id": "0866638e"
      },
      "source": [
        "## Tensor Properties and Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b840f2e5",
      "metadata": {
        "id": "b840f2e5"
      },
      "source": [
        "### Tensor Properties\n",
        "\n",
        "There are several properties that you can leverage to better understand and work with them.\n",
        "\n",
        "\n",
        " - `dtype`: The data type of a tensor tells us the type of data contained in it, such as integers or floats.\n",
        "\n",
        " - `shape`: The shape of a tensor provides the dimensions of the tensor.\n",
        "\n",
        " - `size()`: The `size()` method returns the shape of the tensor. It's an alternative to `shape`.\n",
        "\n",
        " - `dim()`: This tells you the number of dimensions present in the tensor.\n",
        "\n",
        " - `max()/min()`: Get the maximum or minimum value from the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05ab8b2",
      "metadata": {
        "id": "d05ab8b2",
        "outputId": "faec3acf-2a12-469c-de2d-15fc27f25c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of tensor_float: torch.float32\n",
            "Data type of tensor_int: torch.int64\n"
          ]
        }
      ],
      "source": [
        "# dtype\n",
        "\n",
        "tensor_float = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Data type of tensor_float: {tensor_float.dtype}\")\n",
        "\n",
        "tensor_int = torch.tensor([1, 2, 3])\n",
        "print(f\"Data type of tensor_int: {tensor_int.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38154cd2",
      "metadata": {
        "id": "38154cd2",
        "outputId": "df343aed-d3b5-4cc5-b67b-6a9c162a9d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_2d: tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "========================================\n",
            "tensor_3d: tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "tensor_2d = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "print(f\"tensor_2d: {tensor_2d}\")\n",
        "print(\"=\"*40)\n",
        "print(f\"tensor_3d: {tensor_3d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd0edf3e",
      "metadata": {
        "id": "dd0edf3e",
        "outputId": "5af54fff-ad7a-4b76-f943-a942b48db622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor_2d: torch.Size([3, 2])\n",
            "Shape of tensor_3d: torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "# shape\n",
        "print(f\"Shape of tensor_2d: {tensor_2d.shape}\")\n",
        "print(f\"Shape of tensor_3d: {tensor_3d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225d85b8",
      "metadata": {
        "id": "225d85b8",
        "outputId": "de8a020c-c654-40b7-d4f2-2518211bfc3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of tensor_2d: torch.Size([3, 2])\n",
            "Size of tensor_3d: torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "# size()\n",
        "print(f\"Size of tensor_2d: {tensor_2d.size()}\")\n",
        "print(f\"Size of tensor_3d: {tensor_3d.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4372c792",
      "metadata": {
        "id": "4372c792",
        "outputId": "6ba4f091-233f-446a-fe0a-ae61c557d413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of tensor_2d: 2\n",
            "Dimensions of tensor_3d: 3\n"
          ]
        }
      ],
      "source": [
        "# dim()\n",
        "print(f\"Dimensions of tensor_2d: {tensor_2d.dim()}\")\n",
        "print(f\"Dimensions of tensor_3d: {tensor_3d.dim()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ee703f",
      "metadata": {
        "id": "d3ee703f",
        "outputId": "fb79e3f0-9c22-450d-88b7-b7d5ebad0c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max value: 8\n",
            "Min value: 1\n"
          ]
        }
      ],
      "source": [
        "# min/max\n",
        "print(f\"Max value: {tensor_3d.max()}\")\n",
        "print(f\"Min value: {tensor_3d.min()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3194229a",
      "metadata": {
        "id": "3194229a"
      },
      "source": [
        "### Tensor Indexing and Slicing\n",
        "Tensor indexing and slicing is a way to access or modify specific portions of a tensor. It's similar to Python list indexing with some added functionalities to cater to multi-dimensional data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ee2df7",
      "metadata": {
        "id": "d4ee2df7"
      },
      "source": [
        "#### Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a926603",
      "metadata": {
        "id": "7a926603"
      },
      "source": [
        "The basic indexing is similar to the python list or numpy array. we can either indexing a single item or use the negative indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36c358a",
      "metadata": {
        "id": "e36c358a",
        "outputId": "f28e0748-8529-42ce-e6c1-d6434d56cd3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n",
            "tensor(4)\n"
          ]
        }
      ],
      "source": [
        "tensor1d = torch.tensor([0, 1, 2, 3, 4])\n",
        "\n",
        "# Indexing a single item\n",
        "print(tensor1d[2])  # Outputs: 2\n",
        "\n",
        "# Negative indexing\n",
        "print(tensor1d[-1])  # Outputs: 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbceae8d",
      "metadata": {
        "id": "dbceae8d",
        "outputId": "94c61e98-96e0-4310-e70d-c861d5bd8ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "\n",
            "tensor([4, 5, 6])\n",
            "tensor(6)\n"
          ]
        }
      ],
      "source": [
        "tensor2d = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "print(tensor2d)\n",
        "print()\n",
        "# Accessing a specific row\n",
        "print(tensor2d[1])  # Outputs: [4, 5, 6]\n",
        "\n",
        "# Accessing a specific element\n",
        "print(tensor2d[1, 2])  # Outputs: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8061b1",
      "metadata": {
        "id": "ba8061b1",
        "outputId": "32e51a86-c2eb-4332-ece6-b2683830d9d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7]],\n",
            "\n",
            "        [[ 8,  9, 10, 11],\n",
            "         [12, 13, 14, 15]],\n",
            "\n",
            "        [[16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "Access the first batch of tensor3d\n",
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "========================================\n",
            "Access the second element of the first batch of tensor3d\n",
            "tensor([4, 5, 6, 7])\n",
            "========================================\n",
            "Access the third element of the second column of the second batch of tensor3d\n",
            "14\n",
            "========================================\n",
            "Extract a subarray from the third batch of tensor3d\n",
            "tensor([17, 18])\n"
          ]
        }
      ],
      "source": [
        "tensor3d = torch.tensor([\n",
        "                         [[ 0,  1,  2,  3], [ 4,  5,  6,  7]],\n",
        "                         [[ 8,  9, 10, 11], [12, 13, 14, 15]],\n",
        "                         [[16, 17, 18, 19], [20, 21, 22, 23]]\n",
        "                        ])\n",
        "\n",
        "print(tensor3d)\n",
        "\n",
        "# Access the first batch\n",
        "first_batch = tensor3d[0]\n",
        "print(f\"Access the first batch of tensor3d\\n{first_batch}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Access the second element of the first batch\n",
        "second_element_first_batch = tensor3d[0, 1]\n",
        "print(f\"Access the second element of the first batch of tensor3d\\n{second_element_first_batch}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Access the third element of the second column of the second batch\n",
        "element = tensor3d[1, 1, 2]\n",
        "print(f\"Access the third element of the second column of the second batch of tensor3d\\n{element}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Extract a subarray from the third batch\n",
        "subarray = tensor3d[2, 0, 1:3]\n",
        "print(f\"Extract a subarray from the third batch of tensor3d\\n{subarray}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c594cd1",
      "metadata": {
        "id": "4c594cd1"
      },
      "source": [
        "#### Slicing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e2f607",
      "metadata": {
        "id": "56e2f607"
      },
      "source": [
        "Slicing in tensors allows us to extract continuous segments, akin to subsetting lists or arrays in Python, enabling precise and flexible data partitioning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc2d163",
      "metadata": {
        "id": "9cc2d163",
        "outputId": "9805142f-e8c4-4ba1-80e2-521470f6abef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([1, 3])\n"
          ]
        }
      ],
      "source": [
        "simple_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
        "\n",
        "# tensor[start:end:step]\n",
        "print(simple_tensor[1:4])  # Outputs: [1, 2, 3]\n",
        "\n",
        "# tensor[start:end:step]\n",
        "print(simple_tensor[1:4:2])  # Outputs: [1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cd914b",
      "metadata": {
        "id": "c8cd914b"
      },
      "outputs": [],
      "source": [
        "tensor_2d = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e5ef08",
      "metadata": {
        "id": "d8e5ef08",
        "outputId": "3c9b5de4-7131-484c-d22d-470515fb5bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2D tensor \n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "========================================\n",
            "Selecting the first row of 2d tensor using tensor_2d[0] \n",
            "tensor([1, 2])\n",
            "========================================\n",
            "Selecting the first column of 2d tensor using tensor_2d[:, 0] \n",
            "tensor([1, 3, 5])\n",
            "========================================\n",
            "Selecting the first two rows of 2d tensor using tensor_2d[:2] \n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 2D tensor \\n{tensor_2d}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting the row for 2d tensor\n",
        "first_row = tensor_2d[0]\n",
        "print(f\"Selecting the first row of 2d tensor using tensor_2d[0] \\n{first_row}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting the column for 2d tensor\n",
        "first_column = tensor_2d[:, 0]\n",
        "print(f\"Selecting the first column of 2d tensor using tensor_2d[:, 0] \\n{first_column}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting multiple rows\n",
        "first_two_rows = tensor_2d[:2]\n",
        "print(f\"Selecting the first two rows of 2d tensor using tensor_2d[:2] \\n{first_two_rows}\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6bb662",
      "metadata": {
        "id": "0c6bb662",
        "outputId": "af109f87-532c-42a4-9042-a8534acc1519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3D tensor \n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "========================================\n",
            "Selecting the first matrix of 3d tensor using tensor_3d[0] \n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "========================================\n",
            "Selecting the first row across all matrices of 3d tensor using tensor_3d[:, 0] \n",
            "tensor([[1, 2],\n",
            "        [5, 6]])\n",
            "========================================\n",
            "Selecting the first column across all matrices of 3d tensor using tensor_3d[:, :, 0] \n",
            "tensor([[1, 3],\n",
            "        [5, 7]])\n",
            "========================================\n",
            "Selecting a single value from 3d tensor using tensor_3d[1, 0, 1] \n",
            "6\n",
            "========================================\n",
            "Selecting a sub-tensor from 3d tensor using tensor_3d[0, :1] \n",
            "tensor([[1, 2]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 3D tensor \\n{tensor_3d}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting a 2D matrix from 3d tensor\n",
        "first_matrix = tensor_3d[0]\n",
        "print(f\"Selecting the first matrix of 3d tensor using tensor_3d[0] \\n{first_matrix}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting a row across matrices\n",
        "first_row_across_matrices = tensor_3d[:, 0]\n",
        "print(f\"Selecting the first row across all matrices of 3d tensor using tensor_3d[:, 0] \\n{first_row_across_matrices}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting a column across matrices\n",
        "first_column_across_matrices = tensor_3d[:, :, 0]\n",
        "print(f\"Selecting the first column across all matrices of 3d tensor using tensor_3d[:, :, 0] \\n{first_column_across_matrices}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting a single value\n",
        "value = tensor_3d[1, 0, 1]\n",
        "print(f\"Selecting a single value from 3d tensor using tensor_3d[1, 0, 1] \\n{value}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Selecting a sub-tensor\n",
        "sub_tensor = tensor_3d[0, :1]\n",
        "print(f\"Selecting a sub-tensor from 3d tensor using tensor_3d[0, :1] \\n{sub_tensor}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6e3e40",
      "metadata": {
        "id": "3b6e3e40"
      },
      "source": [
        "The `:` here in the `[:, :, 0]` is just a placeholder, that signifies **\"take everything along this dimension.\"** It is used for slicing to specify that all elements along a given dimension should be included. This is very much like the behavior of slicing in Python lists and NumPy arrays.\n",
        "\n",
        "And in the *Selecting the first row across all matrices* example, the `[:, 0]` is equal to `[:, 0, :]`. In PyTorch (as well as in NumPy), when you're slicing into multi-dimensional arrays, if you don't provide indices for all the dimensions, the missing dimensions are considered as complete slices (`:`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bb4243",
      "metadata": {
        "id": "02bb4243"
      },
      "source": [
        "#### Use Cases with Real-world Scenarios\n",
        "\n",
        "1. Extracting the First Token's Embedding in BERT\n",
        "\n",
        "    In transformers like BERT, the embedding of the first token (often `[CLS]`) is typically used as the aggregate sequence representation.\n",
        "\n",
        "    For example, we want to use the output of BERT to do the text classification, here is an example for getting the text representation\n",
        "\n",
        "    ```\n",
        "    # Assume `outputs` is the output from BERT model, having shape [batch_size, sequence_length, hidden_size]\n",
        "    cls_embeddings = outputs[:, 0, :]\n",
        "    ```\n",
        "    \n",
        "<br />\n",
        "\n",
        "2. Splitting a Tensor into Batches\n",
        "\n",
        "    In mini-batch training, you split your data into batches.\n",
        "    ```\n",
        "    data = torch.randn(100, 512)\n",
        "    batch_size = 32\n",
        "\n",
        "    for i in range(0, 100, batch_size):\n",
        "        batch = data[i:i+batch_size]\n",
        "    ```\n",
        "\n",
        "<br />\n",
        "\n",
        "3. Image Downscaling\n",
        "\n",
        "    Downscale an image by taking every nth pixel.\n",
        "    ```\n",
        "    image = torch.randn(1, 3, 256, 256)\n",
        "    downscaled = image[:, :, ::2, ::2]\n",
        "    ```\n",
        "    \n",
        "    <details>\n",
        "        <summary>>Some explaination(Click to expand)</summary>\n",
        "    \n",
        "        `1` - Represents the batch size. This tensor contains one image.\n",
        "    \n",
        "        `3` - Represents the number of channels (typically for RGB images, where 3 channels correspond to Red, Green, and Blue).\n",
        "    \n",
        "        `256` - Height of the image.\n",
        "    \n",
        "        `256` - Width of the image.\n",
        "    \n",
        "        `:` - The first `:` means we are taking all elements along the batch dimension. In this case, it's just one image.\n",
        "    \n",
        "        `:` - The second `:` means we are taking all channels of the image (R, G, B).\n",
        "    \n",
        "        `::2` - The first `::2` means we are taking every second pixel in the height dimension. It effectively halves the height of the image.\n",
        "    \n",
        "        `::2` - The first `::2` means we are taking every second pixel in the width dimension. It effectively halves the width of the image.\n",
        "    \n",
        "    </details>\n",
        "\n",
        "<br />\n",
        "\n",
        "4. Sequence Padding and Truncation in NLP\n",
        "\n",
        "    Pad (or truncate) sequences to a fixed length for batching.\n",
        "    ```\n",
        "    max_length = 50\n",
        "    sequence = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "    if len(sequence) < max_length:\n",
        "        padded_sequence = torch.cat([sequence, torch.zeros(max_length - len(sequence))])\n",
        "    else:\n",
        "        padded_sequence = sequence[:max_length]\n",
        "\n",
        "    ```\n",
        "    \n",
        "<br />\n",
        "\n",
        "5. Selecting Specific Channels in an Image\n",
        "\n",
        "    From an RGB image, extract only the Red channel.\n",
        "    ```\n",
        "    image = torch.randn(1, 3, 256, 256)\n",
        "    red_channel = image[:, 0, :, :]\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a4d4b9",
      "metadata": {
        "id": "29a4d4b9"
      },
      "source": [
        "### Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c710337b",
      "metadata": {
        "id": "c710337b"
      },
      "source": [
        "#### Basic Computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e56a129",
      "metadata": {
        "id": "9e56a129",
        "outputId": "747f021e-018e-48ab-e56f-d543722f1716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([1., 2., 3.])\n",
            "Tensor b: tensor([4., 5., 6.])\n",
            "========================================\n",
            "a + b = tensor([5., 7., 9.])\n",
            "========================================\n",
            "a - b = tensor([-3., -3., -3.])\n",
            "========================================\n",
            "a * b (Element-wise) = tensor([ 4., 10., 18.])\n",
            "========================================\n",
            "a / b (Element-wise) = tensor([0.2500, 0.4000, 0.5000])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "b = torch.tensor([4, 5, 6], dtype=torch.float)\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Addition\n",
        "# also we can use torch.add(a, b) or a+b\n",
        "c = a.add(b)\n",
        "print(f\"a + b = {c}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Subtraction\n",
        "# also we can use torch.sub(a, b) or a-b\n",
        "d = a.sub(b)\n",
        "print(f\"a - b = {d}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Multiplication (Element-wise)\n",
        "# also we can use torch.mul(a, b) or a*b\n",
        "e = a.mul(b)\n",
        "print(f\"a * b (Element-wise) = {e}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Division (Element-wise)\n",
        "# also we can use torch.div(a, b)  or a/b\n",
        "f = a.div(b)\n",
        "print(f\"a / b (Element-wise) = {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa72c000",
      "metadata": {
        "id": "fa72c000"
      },
      "source": [
        "We can find that after all these computations, the value for `a` and `b` won't change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3230d6bb",
      "metadata": {
        "id": "3230d6bb",
        "outputId": "4cabed30-3363-4376-fd58-bbf4dfc7f9f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([1., 2., 3.])\n",
            "Tensor b: tensor([4., 5., 6.])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b806b5",
      "metadata": {
        "id": "56b806b5"
      },
      "source": [
        "So this means that if we want to save the value after the computation, we always need to assign a new variable. Sometimes, we want to keep the changes in the original variable for memory and performance considerations. So, in PyTorch, we can use the in-place operation to do this.\n",
        "\n",
        "In-place operations are a crucial aspect of PyTorch's tensor operations, especially when considering memory management and performance optimization.\n",
        "\n",
        "In PyTorch, in-place operations are methods that have a `_` suffix, like `add_()`, `mul_()`, etc. These operations modify the original tensor directly and do not create a new one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6894a711",
      "metadata": {
        "id": "6894a711",
        "outputId": "c5169d17-7d09-46fb-cfc4-dbd2734aa90b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a after in-place addition: tensor([5., 7., 9.])\n",
            "========================================\n",
            "Tensor a after in-place multiplication by 2: tensor([10., 14., 18.])\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# In-place addition\n",
        "a.add_(b)\n",
        "print(f\"Tensor a after in-place addition: {a}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# In-place multiplication\n",
        "a.mul_(2)\n",
        "print(f\"Tensor a after in-place multiplication by 2: {a}\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b956b6",
      "metadata": {
        "id": "59b956b6",
        "outputId": "a6f848b1-efd5-4cf3-9800-06e2d533e402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a after in-place addition: tensor([ 6.,  9., 12.])\n",
            "========================================\n",
            "Tensor a after in-place multiplication by 2: tensor([1.5000, 1.8000, 2.0000])\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# In-place subtraction\n",
        "a.sub_(b)\n",
        "print(f\"Tensor a after in-place addition: {a}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# In-place division\n",
        "a.div_(b)\n",
        "print(f\"Tensor a after in-place multiplication by 2: {a}\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b0c0462",
      "metadata": {
        "id": "7b0c0462",
        "outputId": "38170f9a-984f-4677-8604-3f7e651883e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor b won't be affected: tensor([4., 5., 6.])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor b won't be affected: {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30bbc45",
      "metadata": {
        "id": "e30bbc45"
      },
      "source": [
        "#### Matrix Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18eed71e",
      "metadata": {
        "id": "18eed71e",
        "outputId": "f7311a50-36f8-438b-9117-a5a5a2a6c037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix M: \n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "Matrix N: \n",
            "tensor([[9., 8., 7.],\n",
            "        [6., 5., 4.]])\n",
            "========================================\n",
            "M x N (Matrix Multiplication): \n",
            "tensor([[21., 18., 15.],\n",
            "        [51., 44., 37.],\n",
            "        [81., 70., 59.]])\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "M = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
        "N = torch.tensor([[9, 8, 7], [6, 5, 4]], dtype=torch.float)\n",
        "print(f\"Matrix M: \\n{M}\")\n",
        "print(f\"Matrix N: \\n{N}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Matrix Multiplication\n",
        "# also we can use  M.mm(N)\n",
        "matmul_result = torch.mm(M, N)\n",
        "print(f\"M x N (Matrix Multiplication): \\n{matmul_result}\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1977e8c2",
      "metadata": {
        "id": "1977e8c2"
      },
      "source": [
        "However, `torch.mm()` and `M.mm(N)` **only** works for **2D tensor**\n",
        "\n",
        "We can use `torch.matmul()` or `M.matmul(N)` for higher dimension, the `matmul` support the not only **2D tensor**, but also **higher dimension**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d715285b",
      "metadata": {
        "id": "d715285b",
        "outputId": "b59bd403-b95e-4e7c-de71-266e7332ade9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch A: \n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "Batch B: \n",
            "tensor([[[2, 0],\n",
            "         [0, 2]],\n",
            "\n",
            "        [[1, 1],\n",
            "         [1, 1]]])\n",
            "========================================\n",
            "Batched matrix multiplication:\n",
            "tensor([[[ 2,  4],\n",
            "         [ 6,  8]],\n",
            "\n",
            "        [[11, 11],\n",
            "         [15, 15]]])\n"
          ]
        }
      ],
      "source": [
        "A_batch = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "B_batch = torch.tensor([[[2, 0], [0, 2]], [[1, 1], [1, 1]]])\n",
        "\n",
        "print(f\"Batch A: \\n{A_batch}\")\n",
        "print(f\"Batch B: \\n{B_batch}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# we can also use A_batch @ B_batch\n",
        "result_batch = torch.matmul(A_batch, B_batch)\n",
        "print(\"Batched matrix multiplication:\")\n",
        "print(result_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78721934",
      "metadata": {
        "id": "78721934"
      },
      "source": [
        "In the above result:\n",
        "\n",
        "The first batch `[[2, 4], [6, 8]]` of the result comes from the matrix multiplication of the first matrix of `A_batch` and `B_batch`, so `[[1, 2], [3, 4]] X [[2, 0], [0, 2]]`\n",
        "\n",
        "The second batch `[[11, 11], [15, 15]]` of the result comes from the matrix multiplication of the second matrix of `A_batch` and `B_batch`, so `[[5, 6], [7, 8]] X [[1, 1], [1, 1]]]`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define two 2D vectors\n",
        "A = np.array([2, 3])\n",
        "B = np.array([-2, -3])\n",
        "\n",
        "# Calculate the dot product\n",
        "dot_product = np.dot(A, B)\n",
        "\n",
        "# Plot the vectors\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.quiver(0, 0, A[0], A[1], angles='xy', scale_units='xy', scale=1, color='blue', label='Vector A')\n",
        "plt.quiver(0, 0, B[0], B[1], angles='xy', scale_units='xy', scale=1, color='red', label='Vector B')\n",
        "plt.xlim(-4, 4)\n",
        "plt.ylim(-4, 4)\n",
        "plt.axhline(0, color='black',linewidth=0.5)\n",
        "plt.axvline(0, color='black',linewidth=0.5)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title(\"Dot Product of Vectors\")\n",
        "plt.text(0.5, 1, f\"Dot Product: {dot_product}\", fontsize=10, bbox=dict(facecolor='none', edgecolor='black'))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI66EtXoMLdi",
        "outputId": "addfd8e0-fcf1-4191-9901-e9f6c8b9139b"
      },
      "id": "nI66EtXoMLdi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# # Define two vectors\n",
        "# A = np.array([2, 3, 4])\n",
        "# B = np.array([5, 6, 7])\n",
        "\n",
        "# # Compute the cross product\n",
        "# cross_product = np.cross(A, B)\n",
        "\n",
        "# # Create a figure and 3D axis\n",
        "# fig = plt.figure(figsize=(8, 8))\n",
        "# ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# # Plot the original vectors\n",
        "# ax.quiver(0, 0, 0, A[0], A[1], A[2], color='blue', label='Vector A')\n",
        "# ax.quiver(0, 0, 0, B[0], B[1], B[2], color='red', label='Vector B')\n",
        "\n",
        "# # Plot the cross product vector\n",
        "# ax.quiver(0, 0, 0, cross_product[0], cross_product[1], cross_product[2], color='green', label='Cross Product')\n",
        "\n",
        "# # Set plot limits\n",
        "# ax.set_xlim([0, max(A[0], B[0], cross_product[0])])\n",
        "# ax.set_ylim([0, max(A[1], B[1], cross_product[1])])\n",
        "# ax.set_zlim([0, max(A[2], B[2], cross_product[2])])\n",
        "\n",
        "# # Set labels and title\n",
        "# ax.set_xlabel('X')\n",
        "# ax.set_ylabel('Y')\n",
        "# ax.set_zlabel('Z')\n",
        "# ax.set_title('Cross Product Visualization')\n",
        "\n",
        "# # Show legend\n",
        "# ax.legend()\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "3lBEtYwfMLWF"
      },
      "id": "3lBEtYwfMLWF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADmhuWjGMLGe"
      },
      "id": "ADmhuWjGMLGe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2y7QdQstMLAw"
      },
      "id": "2y7QdQstMLAw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf7c657",
      "metadata": {
        "id": "6cf7c657",
        "outputId": "7bec4554-a6e7-4a68-df72-8475e2b5aa94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([1., 2., 3.])\n",
            "Tensor b: tensor([4., 5., 6.])\n",
            "========================================\n",
            "Dot Product of a and b: 32.0\n",
            "========================================\n",
            "Norm of a (L2 by default): 3.7416574954986572\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "b = torch.tensor([4, 5, 6], dtype=torch.float)\n",
        "\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Dot Product\n",
        "# also we can use a.dot(b)\n",
        "dot_product = torch.dot(a, b)\n",
        "print(f\"Dot Product of a and b: {dot_product}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Norm (L2 norm by default)\n",
        "# also we can use a.norm()\n",
        "norm_result = torch.norm(a)\n",
        "print(f\"Norm of a (L2 by default): {norm_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc777fc",
      "metadata": {
        "id": "afc777fc"
      },
      "source": [
        "The inputs to `torch.dot` **must be 1D tensors**. And the **sizes** of the two tensors **must be the same**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d23f191c",
      "metadata": {
        "id": "d23f191c"
      },
      "source": [
        "You can compute various norms (L1, L2, etc.) using `torch.norm`.\n",
        "\n",
        "It can operate on multi-dimensional tensors. For a matrix, it will compute the Frobenius norm by default.\n",
        "\n",
        "If you want to compute the norm across specific dimensions, you can specify them using the `dim` parameter.\n",
        "\n",
        "If applied to a multi-dimensional tensor without specifying any dimensions, it will treat the tensor as a flattened 1D tensor and compute the norm accordingly.\n",
        "\n",
        "Here is the official document for torch.norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2efede",
      "metadata": {
        "scrolled": true,
        "id": "9b2efede",
        "outputId": "843dfe86-550d-48a6-b642-c5b3b3565f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function norm in module torch.functional:\n",
            "\n",
            "norm(input, p: Union[float, str, NoneType] = 'fro', dim=None, keepdim=False, out=None, dtype=None)\n",
            "    Returns the matrix norm or vector norm of a given tensor.\n",
            "\n",
            "    .. warning::\n",
            "\n",
            "        torch.norm is deprecated and may be removed in a future PyTorch release.\n",
            "        Its documentation and behavior may be incorrect, and it is no longer\n",
            "        actively maintained.\n",
            "\n",
            "        Use :func:`torch.linalg.vector_norm` when computing vector norms and\n",
            "        :func:`torch.linalg.matrix_norm` when computing matrix norms.\n",
            "        For a function with a similar behavior as this one see :func:`torch.linalg.norm`.\n",
            "        Note, however, the signature for these functions is slightly different than the\n",
            "        signature for ``torch.norm``.\n",
            "\n",
            "    Args:\n",
            "        input (Tensor): The input tensor. Its data type must be either a floating\n",
            "            point or complex type. For complex inputs, the norm is calculated using the\n",
            "            absolute value of each element. If the input is complex and neither\n",
            "            :attr:`dtype` nor :attr:`out` is specified, the result's data type will\n",
            "            be the corresponding floating point type (e.g. float if :attr:`input` is\n",
            "            complexfloat).\n",
            "\n",
            "        p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: ``'fro'``\n",
            "            The following norms can be calculated:\n",
            "\n",
            "            ======  ==============  ==========================\n",
            "            ord     matrix norm     vector norm\n",
            "            ======  ==============  ==========================\n",
            "            'fro'   Frobenius norm  --\n",
            "            'nuc'   nuclear norm    --\n",
            "            Number  --              sum(abs(x)**ord)**(1./ord)\n",
            "            ======  ==============  ==========================\n",
            "\n",
            "            The vector norm can be calculated across any number of dimensions.\n",
            "            The corresponding dimensions of :attr:`input` are flattened into\n",
            "            one dimension, and the norm is calculated on the flattened\n",
            "            dimension.\n",
            "\n",
            "            Frobenius norm produces the same result as ``p=2`` in all cases\n",
            "            except when :attr:`dim` is a list of three or more dims, in which\n",
            "            case Frobenius norm throws an error.\n",
            "\n",
            "            Nuclear norm can only be calculated across exactly two dimensions.\n",
            "\n",
            "        dim (int, tuple of ints, list of ints, optional):\n",
            "            Specifies which dimension or dimensions of :attr:`input` to\n",
            "            calculate the norm across. If :attr:`dim` is ``None``, the norm will\n",
            "            be calculated across all dimensions of :attr:`input`. If the norm\n",
            "            type indicated by :attr:`p` does not support the specified number of\n",
            "            dimensions, an error will occur.\n",
            "        keepdim (bool, optional): whether the output tensors have :attr:`dim`\n",
            "            retained or not. Ignored if :attr:`dim` = ``None`` and\n",
            "            :attr:`out` = ``None``. Default: ``False``\n",
            "        out (Tensor, optional): the output tensor. Ignored if\n",
            "            :attr:`dim` = ``None`` and :attr:`out` = ``None``.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of\n",
            "            returned tensor. If specified, the input tensor is casted to\n",
            "            :attr:`dtype` while performing the operation. Default: None.\n",
            "\n",
            "    .. note::\n",
            "        Even though ``p='fro'`` supports any number of dimensions, the true\n",
            "        mathematical definition of Frobenius norm only applies to tensors with\n",
            "        exactly two dimensions. :func:`torch.linalg.matrix_norm` with ``ord='fro'``\n",
            "        aligns with the mathematical definition, since it can only be applied across\n",
            "        exactly two dimensions.\n",
            "\n",
            "    Example::\n",
            "\n",
            "        >>> import torch\n",
            "        >>> a = torch.arange(9, dtype= torch.float) - 4\n",
            "        >>> b = a.reshape((3, 3))\n",
            "        >>> torch.norm(a)\n",
            "        tensor(7.7460)\n",
            "        >>> torch.norm(b)\n",
            "        tensor(7.7460)\n",
            "        >>> torch.norm(a, float('inf'))\n",
            "        tensor(4.)\n",
            "        >>> torch.norm(b, float('inf'))\n",
            "        tensor(4.)\n",
            "        >>> c = torch.tensor([[ 1, 2, 3], [-1, 1, 4]] , dtype=torch.float)\n",
            "        >>> torch.norm(c, dim=0)\n",
            "        tensor([1.4142, 2.2361, 5.0000])\n",
            "        >>> torch.norm(c, dim=1)\n",
            "        tensor([3.7417, 4.2426])\n",
            "        >>> torch.norm(c, p=1, dim=1)\n",
            "        tensor([6., 6.])\n",
            "        >>> d = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)\n",
            "        >>> torch.norm(d, dim=(1, 2))\n",
            "        tensor([ 3.7417, 11.2250])\n",
            "        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n",
            "        (tensor(3.7417), tensor(11.2250))\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(torch.norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be845c2",
      "metadata": {
        "id": "6be845c2"
      },
      "source": [
        "#### Conversions and Reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c1ea91",
      "metadata": {
        "id": "83c1ea91",
        "outputId": "22dd8d81-1ed4-4ce4-e4df-7e93e78f4975",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([1., 2., 3.])\n",
            "========================================\n",
            "Tensor a converted to Numpy: [1. 2. 3.]\n",
            "========================================\n",
            "Reshaped Tensor (3x1): \n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "========================================\n",
            "Viewed Tensor (similar to reshape, 3x1): \n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# Sample tensors for demonstration\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Convert to Numpy\n",
        "numpy_array = a.numpy()\n",
        "print(f\"Tensor a converted to Numpy: {numpy_array}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Reshape\n",
        "reshaped_tensor = a.reshape(3, 1)\n",
        "print(f\"Reshaped Tensor (3x1): \\n{reshaped_tensor}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# View (similar to reshape)\n",
        "viewed_tensor = a.view(3, 1)\n",
        "print(f\"Viewed Tensor (similar to reshape, 3x1): \\n{viewed_tensor}\")\n",
        "print(\"=\"*40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3aa91f1",
      "metadata": {
        "id": "c3aa91f1"
      },
      "source": [
        " Both `view` and `reshape` return tensors that share the same underlying data with the original tensor, unless a data copy is made. This means that if you modify the original tensor, any tensors derived from it via `view` or `reshape` (when they don't involve a data copy) will also reflect those changes. Similarly, if you modify the reshaped or viewed tensor, the original tensor will change as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece39af0",
      "metadata": {
        "id": "ece39af0",
        "outputId": "bc6d9b28-3875-4bc6-8469-91ccf854cc93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal Tensor a: tensor([1., 2., 3.])\n",
            "========================================\n",
            "Modified original tensor:\n",
            "tensor([99.,  2.,  3.])\n",
            "========================================\n",
            "Viewed tensor:\n",
            "tensor([[99.],\n",
            "        [ 2.],\n",
            "        [ 3.]])\n",
            "========================================\n",
            "Reshaped tensor:\n",
            "tensor([[99.],\n",
            "        [ 2.],\n",
            "        [ 3.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Orignal Tensor a: {a}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# modify the original tensor\n",
        "a[0] = 99\n",
        "\n",
        "print(\"Modified original tensor:\")\n",
        "print(a)\n",
        "print(\"=\"*40)\n",
        "print(\"Viewed tensor:\")\n",
        "print(viewed_tensor)\n",
        "print(\"=\"*40)\n",
        "print(\"Reshaped tensor:\")\n",
        "print(reshaped_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c092078",
      "metadata": {
        "id": "9c092078",
        "outputId": "0132d936-08be-42d0-a541-3ca951a14092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal Tensor a: tensor([99.,  2.,  3.])\n",
            "========================================\n",
            "Modified original tensor:\n",
            "tensor([99., 50.,  3.])\n",
            "========================================\n",
            "Viewed tensor:\n",
            "tensor([[99.],\n",
            "        [50.],\n",
            "        [ 3.]])\n",
            "========================================\n",
            "Reshaped tensor:\n",
            "tensor([[99.],\n",
            "        [50.],\n",
            "        [ 3.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Orignal Tensor a: {a}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# modify the reshaped or viewed tensor\n",
        "viewed_tensor[1] = 50\n",
        "\n",
        "print(\"Modified original tensor:\")\n",
        "print(a)\n",
        "print(\"=\"*40)\n",
        "print(\"Viewed tensor:\")\n",
        "print(viewed_tensor)\n",
        "print(\"=\"*40)\n",
        "print(\"Reshaped tensor:\")\n",
        "print(reshaped_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789733ba",
      "metadata": {
        "id": "789733ba",
        "outputId": "24a2b50b-ba03-43eb-fb34-edece744040e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value from one_element_tensor: 5\n"
          ]
        }
      ],
      "source": [
        "# Item (converts a 1-element tensor to a Python scalar)\n",
        "one_element_tensor = torch.tensor([[[[5]]]])\n",
        "scalar = one_element_tensor.item()\n",
        "print(f\"Scalar value from one_element_tensor: {scalar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66f54ab8",
      "metadata": {
        "id": "66f54ab8"
      },
      "source": [
        "`item` **only** works with tensor which **only has one element**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13f5cfa",
      "metadata": {
        "id": "c13f5cfa"
      },
      "source": [
        "#### Transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9adff8d5",
      "metadata": {
        "id": "9adff8d5",
        "outputId": "d5507f7f-4ed3-437f-be3a-74934c0603fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix M: \n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "========================================\n",
            "Transposed Matrix of M: \n",
            "tensor([[1., 3., 5.],\n",
            "        [2., 4., 6.]])\n"
          ]
        }
      ],
      "source": [
        "M = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
        "transposed_matrix = M.t()\n",
        "print(f\"Matrix M: \\n{M}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "\n",
        "print(f\"Transposed Matrix of M: \\n{transposed_matrix}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a78cf7a",
      "metadata": {
        "id": "7a78cf7a"
      },
      "source": [
        "We can also use the `transpose` and `permute` to do the transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697c823e",
      "metadata": {
        "id": "697c823e",
        "outputId": "85ee1ee0-c2a9-4399-8f5d-0e0410fbbc0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposed Matrix of M: \n",
            "tensor([[1., 3., 5.],\n",
            "        [2., 4., 6.]])\n"
          ]
        }
      ],
      "source": [
        "transposed_tensor = M.transpose(0, 1)  # Swapping dimension 0 with dimension 1\n",
        "print(f\"Transposed Matrix of M: \\n{transposed_matrix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36bce50",
      "metadata": {
        "id": "b36bce50",
        "outputId": "249ace7c-d5b5-46cc-a277-d7710fe66696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transposed Matrix of M: \n",
            "tensor([[1., 3., 5.],\n",
            "        [2., 4., 6.]])\n"
          ]
        }
      ],
      "source": [
        "permuted_tensor = M.permute(1, 0)\n",
        "print(f\"Transposed Matrix of M: \\n{transposed_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eb9a3ab",
      "metadata": {
        "id": "9eb9a3ab"
      },
      "source": [
        "We can see the order of the parameter for `permute` and `transposed` is a different, the reason is:\n",
        " - transpose(dim0, dim1):\n",
        "    - This method swaps two specified dimensions (dim0 and dim1).\n",
        "    - For a 2D tensor (matrix), if you want to transpose it, you swap the rows and columns, so you use transpose(0, 1).\n",
        "\n",
        "- permute(*dims):\n",
        "    - This method allows for more general rearrangements of dimensions.\n",
        "    - The argument to permute is a sequence of dimension indices.\n",
        "    - For a 2D tensor, permute(1, 0) means you want the second dimension (index 1) to become the first, and the first dimension (index 0) to become the second."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d882cc",
      "metadata": {
        "id": "53d882cc"
      },
      "source": [
        "Here is the comparison between these three transpose methods:\n",
        "\n",
        "| Function   | Application              | Syntax                                     | Limitations                                                                                      | Use-Case                             |\n",
        "|------------|--------------------------|--------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------|\n",
        "| `t`        | Transposing matrices     | `torch.t(tensor)` or `tensor.t()`          | Only works for 2D tensors.                                                                       | Quick transposition of 2D matrices.   |\n",
        "| `transpose`| Transposing dimensions   | `torch.transpose(tensor, dim0, dim1)`<br>or `tensor.transpose(dim0, dim1)`| Requires specifying two dimensions to swap.                                                     | Transposing any two specific dimensions. Useful for 2D tensors and beyond.   |\n",
        "| `permute`  | Rearranging dimensions   | `tensor.permute(*dims)`                    | Requires specifying all dimensions in the new order.                                            | Rearranging order of all dimensions, especially useful for tensors with more than 2 dimensions. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de0a389",
      "metadata": {
        "id": "7de0a389"
      },
      "source": [
        "Example for `transpose` and `permute` in higher dimension tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b84b440",
      "metadata": {
        "scrolled": true,
        "id": "0b84b440",
        "outputId": "fe86ebe3-b01a-478d-d7f5-6d81402e00c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original 3D tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "\n",
            "The shape of original 3D tensor:torch.Size([2, 3, 4])\n",
            "============================================================\n",
            "switch the 0th and 2nd dimensions using transpose\n",
            "The transposed 3D tensor:\n",
            " tensor([[[ 0, 12],\n",
            "         [ 4, 16],\n",
            "         [ 8, 20]],\n",
            "\n",
            "        [[ 1, 13],\n",
            "         [ 5, 17],\n",
            "         [ 9, 21]],\n",
            "\n",
            "        [[ 2, 14],\n",
            "         [ 6, 18],\n",
            "         [10, 22]],\n",
            "\n",
            "        [[ 3, 15],\n",
            "         [ 7, 19],\n",
            "         [11, 23]]])\n",
            "\n",
            "The shape of transposed 3D tensor:torch.Size([4, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "X = torch.arange(0,24).reshape(2, 3, 4)\n",
        "\n",
        "print(f\"The original 3D tensor:\\n {X}\")\n",
        "print(f\"\\nThe shape of original 3D tensor:{X.shape}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# switch the 0th and 2nd dimensions\n",
        "print(\"switch the 0th and 2nd dimensions using transpose\")\n",
        "transposed_tensor = X.transpose(0, 2)\n",
        "print(f\"The transposed 3D tensor:\\n {transposed_tensor}\")\n",
        "print(f\"\\nThe shape of transposed 3D tensor:{transposed_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bc566f",
      "metadata": {
        "scrolled": true,
        "id": "f8bc566f",
        "outputId": "2d91345a-0b34-4d29-ba73-745d9b080a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original 3D tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "\n",
            "The shape of original 3D tensor:torch.Size([2, 3, 4])\n",
            "============================================================\n",
            "switch the 1st and 2nd dimensions using transpose\n",
            "The transposed 3D tensor:\n",
            " tensor([[[ 0,  4,  8],\n",
            "         [ 1,  5,  9],\n",
            "         [ 2,  6, 10],\n",
            "         [ 3,  7, 11]],\n",
            "\n",
            "        [[12, 16, 20],\n",
            "         [13, 17, 21],\n",
            "         [14, 18, 22],\n",
            "         [15, 19, 23]]])\n",
            "\n",
            "The shape of transposed 3D tensor:torch.Size([2, 4, 3])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The original 3D tensor:\\n {X}\")\n",
        "print(f\"\\nThe shape of original 3D tensor:{X.shape}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# switch the 1st and 2nd dimensions\n",
        "print(\"switch the 1st and 2nd dimensions using transpose\")\n",
        "transposed_tensor2 = X.transpose(1, 2)\n",
        "print(f\"The transposed 3D tensor:\\n {transposed_tensor2}\")\n",
        "print(f\"\\nThe shape of transposed 3D tensor:{transposed_tensor2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558a1797",
      "metadata": {
        "scrolled": true,
        "id": "558a1797",
        "outputId": "53424dc2-b237-4dd6-baca-3ffd14b01460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original 3D tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "\n",
            "The shape of original 3D tensor:torch.Size([2, 3, 4])\n",
            "============================================================\n",
            "rearrange the order of dimensions using permute\n",
            "The transposed 3D tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [12, 13, 14, 15]],\n",
            "\n",
            "        [[ 4,  5,  6,  7],\n",
            "         [16, 17, 18, 19]],\n",
            "\n",
            "        [[ 8,  9, 10, 11],\n",
            "         [20, 21, 22, 23]]])\n",
            "\n",
            "The shape of transposed 3D tensor:torch.Size([3, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The original 3D tensor:\\n {X}\")\n",
        "print(f\"\\nThe shape of original 3D tensor:{X.shape}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# rearrange the order of dimensions\n",
        "print(\"rearrange the order of dimensions using permute\")\n",
        "permuted_tensor = X.permute(1, 0, 2)\n",
        "print(f\"The transposed 3D tensor:\\n {permuted_tensor}\")\n",
        "print(f\"\\nThe shape of transposed 3D tensor:{permuted_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c4cbd4",
      "metadata": {
        "id": "17c4cbd4",
        "outputId": "92c64379-7d12-4b0e-afdb-2cd3e37987cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original 3D tensor:\n",
            " tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n",
            "\n",
            "The shape of original 3D tensor:torch.Size([2, 3, 4])\n",
            "============================================================\n",
            "rearrange the order of dimensions using permute\n",
            "The transposed 3D tensor:\n",
            " tensor([[[ 0,  4,  8],\n",
            "         [12, 16, 20]],\n",
            "\n",
            "        [[ 1,  5,  9],\n",
            "         [13, 17, 21]],\n",
            "\n",
            "        [[ 2,  6, 10],\n",
            "         [14, 18, 22]],\n",
            "\n",
            "        [[ 3,  7, 11],\n",
            "         [15, 19, 23]]])\n",
            "\n",
            "The shape of transposed 3D tensor:torch.Size([4, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The original 3D tensor:\\n {X}\")\n",
        "print(f\"\\nThe shape of original 3D tensor:{X.shape}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# rearrange the order of dimensions\n",
        "print(\"rearrange the order of dimensions using permute\")\n",
        "permuted_tensor2 = X.permute(2, 0, 1)\n",
        "print(f\"The transposed 3D tensor:\\n {permuted_tensor2}\")\n",
        "print(f\"\\nThe shape of transposed 3D tensor:{permuted_tensor2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e33b894",
      "metadata": {
        "id": "6e33b894"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ae456b64",
        "3194229a",
        "c710337b",
        "e30bbc45"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}