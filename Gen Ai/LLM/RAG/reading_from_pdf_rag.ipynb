{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDAB0Ou/VCg6PJODFiLrAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renmsd/portfoilo/blob/main/Gen%20Ai/LLM/RAG/reading_from_pdf_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf sentence-transformers chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6-mauSWT6CW",
        "outputId": "48ecb5a3-5454-4384-f3c3-22959da76d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=dab4e7ba3b32446c258e5f8cf8241c4f00a9b1e6524dbb324fdf1d3283a17a49\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pypdf, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, coloredlogs, posthog, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.1 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypdf-6.1.1 pypika-0.48.9 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb, re, math\n",
        "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
      ],
      "metadata": {
        "id": "SzCDaq3eT38N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55DaACgzTyCQ",
        "outputId": "7ceedc1b-2529-4093-b08a-230d9c21fffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[p.2] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ﺷﺭﻛﺔ( )ﻣﺳﺎﻫﻣﺔ ( ﻣﺭﺍﺟﻌﺔ ﻏﻳﺭ )ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ ﻓﻲ ﺍﻟﻣﻧﺗﻬﻳﺔ ﺃﺷﻬﺭ ﺍﻟﺛﻼﺛﺔ ١٣ﻟﻔﺗﺭﺓ ٥٢٠٢ﻣﺎﺭﺱ ﺍﻟﺻﻔﺣﺎﺕ ﺍﻟﻣﺳﺗﻘﻝ ﺍﻟﻣﺭﺍﺟﻊ ﻓﺣﺹ ﺗﻘﺭﻳﺭ ١ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻲ ﺍﻟﻣﺭﻛ…  (score=0.225)\n",
            "[p.1] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ( ﻣﺭﺍﺟﻌﺔ ﻏﻳﺭ )ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ ﻓﻲ ﺍﻟﻣﻧﺗﻬﻳﺔ ﺃﺷﻬﺭ ﺍﻟﺛﻼﺛﺔ ١٣ﻟﻔﺗﺭﺓ ٥٢٠٢ﻣﺎﺭﺱ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ ﻓﺣﺹ ﺣﻭﻝ ﻭﺗﻘﺭﻳﺭ…  (score=0.230)\n",
            "[p.15] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ٣١ ٠١ ﺍﻟﻘﻁﺎﻋﻳﺔ ﻭﺍﻟﺗﻘﺎﺭﻳﺭ ﺍﻹﻳﺭﺍﺩﺍﺕ( ﺗﺗﻣﺔ) ﻋﻘﻭﺩ ﻣﻁﻠﻭﺑﺎ…  (score=0.231)\n",
            "[p.9] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ٧ ٢( ﺗﺗﻣﺔ )ﺍﻹﻋﺩﺍﺩ ﺃﺳﺱ ٢-٣ ﺍﻟﺣﺎﻟﻳﺔ ﺍﻟﺗﻘﺭﻳﺭ ﻓﺗﺭﺓ ﻓﻲ ﺍﻟ…  (score=0.231)\n"
          ]
        }
      ],
      "source": [
        "PDF_PATH = \"/content/7606_0_2025-06-18_13-35-36_Ar.pdf\"   # <-- set path\n",
        "\n",
        "# 1) Extract text per page (keeps page numbers for citations)\n",
        "def extract_pages(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    pages = []\n",
        "    for i, page in enumerate(reader.pages, start=1):\n",
        "        text = page.extract_text() or \"\"\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        pages.append({\"page\": i, \"text\": text})\n",
        "    return pages\n",
        "\n",
        "pages = extract_pages(PDF_PATH)\n",
        "\n",
        "# 2) Chunking (token-agnostic, word-based; simple & robust)\n",
        "def chunk_page_text(text, max_words=350, overlap=60):\n",
        "    words = text.split()\n",
        "    out = []\n",
        "    step = max(1, max_words - overlap)\n",
        "    for i in range(0, max(1, len(words)), step):\n",
        "        chunk = \" \".join(words[i:i+max_words]).strip()\n",
        "        if chunk:\n",
        "            out.append(chunk)\n",
        "    return out\n",
        "\n",
        "docs, metadatas, ids = [], [], []\n",
        "for p in pages:\n",
        "    chunks = chunk_page_text(p[\"text\"], max_words=350, overlap=60)\n",
        "    for j, ch in enumerate(chunks):\n",
        "        docs.append(ch)\n",
        "        metadatas.append({\"source\": PDF_PATH, \"page\": p[\"page\"], \"chunk\": j})\n",
        "        ids.append(f\"{p['page']:04d}-{j:04d}\")\n",
        "\n",
        "# 3) Embeddings + Vector store (Chroma, local persistence)\n",
        "emb_model = \"intfloat/multilingual-e5-small\"  # good for AR/EN\n",
        "embed_fn = SentenceTransformerEmbeddingFunction(model_name=emb_model)\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")   # folder for persistence\n",
        "coll = client.get_or_create_collection(\n",
        "    name=\"pdf_kb\",\n",
        "    embedding_function=embed_fn,\n",
        "    metadata={\"hnsw:space\": \"cosine\"}  # cosine works well with e5 (it normalizes internally)\n",
        ")\n",
        "\n",
        "# (re)ingest (idempotent-ish: clear if re-running)\n",
        "try:\n",
        "    coll.delete(ids=ids)\n",
        "except Exception:\n",
        "    pass\n",
        "coll.add(ids=ids, documents=docs, metadatas=metadatas)\n",
        "\n",
        "# 4) Retrieval helper\n",
        "def retrieve(query, k=5, where=None):\n",
        "    q = f\"query: {query}\"  # e5-style queries\n",
        "    res = coll.query(query_texts=[q], n_results=k, where=where) # Removed the or {} from where=where or {}\n",
        "    hits = []\n",
        "    for i in range(len(res[\"ids\"][0])):\n",
        "        hits.append({\n",
        "            \"id\": res[\"ids\"][0][i],\n",
        "            \"text\": res[\"documents\"][0][i],\n",
        "            \"meta\": res[\"metadatas\"][0][i],\n",
        "            \"score\": res[\"distances\"][0][i],  # smaller is closer with cosine in Chroma\n",
        "        })\n",
        "    return hits\n",
        "\n",
        "# 5) Try a query\n",
        "hits = retrieve(\"What does the report say about total revenues in Q1 2025?\", k=4)\n",
        "for h in hits:\n",
        "    print(f\"[p.{h['meta']['page']}] {h['text'][:180]}…  (score={h['score']:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hits = retrieve(\"كم كانت مطلوبات العقود \", k=4)\n",
        "for h in hits:\n",
        "    print(f\"[p.{h['meta']['page']}] {h['text'][:180]}…  (score={h['score']:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnhY9jX2WAvm",
        "outputId": "ab385776-85c3-4b46-f76d-4f1982498d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[p.7] )٦١١٫٤١٢٫٥٣ ( )٧٨٣٫٦٦٢٫٨٩٣ ( ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ ﺍﻟﻧﻘﺩ ﻲﻓ ﺍﻟﺯﻳﺎﺩﺓ (ﺍﻟﻧﻘﺹ) ﻲﺎﻓﺻ )٠٧٣٫٩١١٫٧٣ ( ٠٩٠٫٩٦٩٫٢٦ ﺓﺍﻟﻔﺗﺭ ﺑﺩﺍﻳﺔ ﻲﻓ ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ ﻧﻘﺩ ٨٧٣٫٦٢٣٫٠٠٧٫١ ٩٩٣٫٨٨٤٫٠٥٤١ ﺍﻟﻔﺗﺭﺓ ﻧﻬﺎﻳﺔ ﻲﻓ ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ …  (score=0.149)\n",
            "[p.4] ٢ ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻲ ﺍﻟﻣﺭﻛﺯ ﻗﺎﺋﻣﺔ ﺟﻣﻳﻊ()ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺇﻳﺿﺎﺡ ﻓﻲ ١٣ﻛﻣﺎ ﻣﺎﺭﺱ ﻓﻲ ١٣ﻛﻣﺎ ﺩﻳﺳﻣﺑﺭ ٥٢٠٢ ٤٢٠٢ ﺍﻟﻣﻭﺟﻭﺩﺍﺕ (ﻣﺭﺍﺟﻌ…  (score=0.155)\n",
            "[p.13] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ١١ ٦ ﺇﻳﺟﺎﺭﻳﺔ ﻭﻣﻁﻠﻭﺑﺎﺕ ﺍﻻﺳﺗﺧﺩﺍﻡ ﺣﻖ ﻣﻭﺟﻭﺩﺍﺕ ٦-١ ﺍﻻﺳﺗﺧﺩ…  (score=0.158)\n",
            "[p.15] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ٣١ ٠١ ﺍﻟﻘﻁﺎﻋﻳﺔ ﻭﺍﻟﺗﻘﺎﺭﻳﺭ ﺍﻹﻳﺭﺍﺩﺍﺕ( ﺗﺗﻣﺔ) ﻋﻘﻭﺩ ﻣﻁﻠﻭﺑﺎ…  (score=0.166)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2017f60",
        "outputId": "9cd89200-6b86-4663-e3fa-75ec88b66cee"
      },
      "source": [
        "import sys\n",
        "\n",
        "# Try printing with explicit UTF-8 encoding\n",
        "for h in hits:\n",
        "    print(f\"[p.{h['meta']['page']}] {h['text'][:180].encode('utf-8').decode('utf-8')}…  (score={h['score']:.3f})\")\n",
        "\n",
        "# You can also try changing the default encoding for the output\n",
        "# sys.stdout.reconfigure(encoding='utf-8')\n",
        "# Then re-run the previous print loop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[p.7] )٦١١٫٤١٢٫٥٣ ( )٧٨٣٫٦٦٢٫٨٩٣ ( ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ ﺍﻟﻧﻘﺩ ﻲﻓ ﺍﻟﺯﻳﺎﺩﺓ (ﺍﻟﻧﻘﺹ) ﻲﺎﻓﺻ )٠٧٣٫٩١١٫٧٣ ( ٠٩٠٫٩٦٩٫٢٦ ﺓﺍﻟﻔﺗﺭ ﺑﺩﺍﻳﺔ ﻲﻓ ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ ﻧﻘﺩ ٨٧٣٫٦٢٣٫٠٠٧٫١ ٩٩٣٫٨٨٤٫٠٥٤١ ﺍﻟﻔﺗﺭﺓ ﻧﻬﺎﻳﺔ ﻲﻓ ﻳﻣﺎﺛﻠﻪ ﻭﻣﺎ …  (score=0.149)\n",
            "[p.4] ٢ ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻲ ﺍﻟﻣﺭﻛﺯ ﻗﺎﺋﻣﺔ ﺟﻣﻳﻊ()ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺇﻳﺿﺎﺡ ﻓﻲ ١٣ﻛﻣﺎ ﻣﺎﺭﺱ ﻓﻲ ١٣ﻛﻣﺎ ﺩﻳﺳﻣﺑﺭ ٥٢٠٢ ٤٢٠٢ ﺍﻟﻣﻭﺟﻭﺩﺍﺕ (ﻣﺭﺍﺟﻌ…  (score=0.155)\n",
            "[p.13] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ١١ ٦ ﺇﻳﺟﺎﺭﻳﺔ ﻭﻣﻁﻠﻭﺑﺎﺕ ﺍﻻﺳﺗﺧﺩﺍﻡ ﺣﻖ ﻣﻭﺟﻭﺩﺍﺕ ٦-١ ﺍﻻﺳﺗﺧﺩ…  (score=0.158)\n",
            "[p.15] ﻧﺎﺱ ﻁﻳﺭﺍﻥ ﺷﺭﻛﺔ ( ﻣﺳﺎﻫﻣﺔ ﺷﺭﻛﺔ) ﺣﻭﻝ ﺇﻳﺿﺎﺣﺎﺕ ﺍﻟﻣﻭﺟﺯﺓ ﺍﻷﻭﻟﻳﺔ ﺍﻟﻣﺎﻟﻳﺔ ﺍﻟﻣﻌﻠﻭﻣﺎﺕ (ﺫﻟﻙ ﻏﻳﺭ ﻳﺫﻛﺭ ﻟﻡ ﻣﺎ ﺍﻟﺳﻌﻭﺩﻳﺔ ﺑﺎﻟﺭﻳﺎﻻﺕ ﺍﻟﻣﺑﺎﻟﻎ ﺟﻣﻳﻊ ) ٣١ ٠١ ﺍﻟﻘﻁﺎﻋﻳﺔ ﻭﺍﻟﺗﻘﺎﺭﻳﺭ ﺍﻹﻳﺭﺍﺩﺍﺕ( ﺗﺗﻣﺔ) ﻋﻘﻭﺩ ﻣﻁﻠﻭﺑﺎ…  (score=0.166)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d10909",
        "outputId": "0098359f-6756-4b18-a941-9ed9cabdf30d"
      },
      "source": [
        "!pip install caas-jupyter-tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement caas-jupyter-tools (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for caas-jupyter-tools\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF → Table rows (verbatim + normalized) extractor\n",
        "# - Reads the uploaded Arabic PDF\n",
        "# - Extracts tables per page using pdfplumber (fallback to page text if tables not detected)\n",
        "# - Produces a row-level CSV with both verbatim and normalized digits\n",
        "# - Adds useful metadata: page, table_idx, row_idx, col_idx, context_before (snippet from page)\n",
        "#\n",
        "# Files saved:\n",
        "# - /mnt/data/pdf_table_rows.csv\n",
        "# - /mnt/data/pdf_page_text.csv\n",
        "#\n",
        "# The code will also preview a few extracted rows.\n",
        "\n",
        "import os, re, json\n",
        "from typing import List, Dict, Any\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "PDF_PATH = \"7606_0_2025-06-18_13-35-36_Ar.pdf\"\n",
        "\n",
        "# Digit normalization (Arabic-Indic to ASCII); also normalize decimal/group separators\n",
        "TRANS = str.maketrans(\"٠١٢٣٤٥٦٧٨٩٬٫\", \"0123456789,.\")\n",
        "def normalize_nums(s: str) -> str:\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    return str(s).translate(TRANS)\n",
        "\n",
        "def try_import_pdfplumber():\n",
        "    try:\n",
        "        import pdfplumber  # type: ignore\n",
        "        return pdfplumber\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def extract_with_pdfplumber(pdf_path: str):\n",
        "    pdfplumber = try_import_pdfplumber()\n",
        "    if not pdfplumber:\n",
        "        return None, None\n",
        "\n",
        "    rows = []\n",
        "    pages_meta = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for p_idx, page in enumerate(pdf.pages, start=1):\n",
        "            # Store a light page text for \"context_before\"\n",
        "            page_text = (page.extract_text() or \"\").strip()\n",
        "            page_text = re.sub(r\"\\s+\", \" \", page_text)\n",
        "            pages_meta.append({\"page\": p_idx, \"text\": page_text})\n",
        "            # Detect tables\n",
        "            try:\n",
        "                tables = page.extract_tables()\n",
        "            except Exception:\n",
        "                tables = []\n",
        "            if not tables:\n",
        "                continue\n",
        "            for t_idx, tbl in enumerate(tables):\n",
        "                # tbl is a list of rows; each row is a list of cells (strings/None)\n",
        "                for r_idx, row in enumerate(tbl):\n",
        "                    # Create one record per cell to allow fine-grained retrieval (row-level + cell-level)\n",
        "                    for c_idx, cell in enumerate(row):\n",
        "                        v_text = \"\" if cell is None else str(cell).strip()\n",
        "                        n_text = normalize_nums(v_text)\n",
        "                        # Skip empty cells to reduce noise, but keep non-empty rows\n",
        "                        rows.append({\n",
        "                            \"page\": p_idx,\n",
        "                            \"table_idx\": t_idx,\n",
        "                            \"row_idx\": r_idx,\n",
        "                            \"col_idx\": c_idx,\n",
        "                            \"cell_text_verbatim\": v_text,\n",
        "                            \"cell_text_normalized\": n_text,\n",
        "                            \"row_join_verbatim\": \" | \".join([(\"\" if x is None else str(x).strip()) for x in row]),\n",
        "                            \"row_join_normalized\": normalize_nums(\" | \".join([(\"\" if x is None else str(x).strip()) for x in row])),\n",
        "                            \"context_before\": page_text[:200]\n",
        "                        })\n",
        "    return rows, pages_meta\n",
        "\n",
        "# Fallback: extract only page text using PyPDF if pdfplumber isn't available\n",
        "def extract_with_pypdf(pdf_path: str):\n",
        "    try:\n",
        "        from pypdf import PdfReader\n",
        "    except Exception:\n",
        "        return None, None\n",
        "    reader = PdfReader(pdf_path)\n",
        "    pages_meta = []\n",
        "    for p_idx, page in enumerate(reader.pages, start=1):\n",
        "        text = page.extract_text() or \"\"\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        pages_meta.append({\"page\": p_idx, \"text\": text})\n",
        "    return [], pages_meta\n",
        "\n",
        "rows, pages_meta = extract_with_pdfplumber(PDF_PATH)\n",
        "\n",
        "if rows is None:\n",
        "    # pdfplumber not available; fallback to text-only\n",
        "    rows, pages_meta = extract_with_pypdf(PDF_PATH)\n",
        "\n",
        "# Save page texts regardless (for context / troubleshooting)\n",
        "df_pages = pd.DataFrame(pages_meta or [])\n",
        "df_pages.to_csv(\"pdf_page_text.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Save table rows if any; otherwise create an empty frame with schema\n",
        "if rows:\n",
        "    df_rows = pd.DataFrame(rows)\n",
        "else:\n",
        "    df_rows = pd.DataFrame(columns=[\n",
        "        \"page\",\"table_idx\",\"row_idx\",\"col_idx\",\n",
        "        \"cell_text_verbatim\",\"cell_text_normalized\",\n",
        "        \"row_join_verbatim\",\"row_join_normalized\",\"context_before\"\n",
        "    ])\n",
        "\n",
        "df_rows.to_csv(\"pdf_table_rows.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Preview a few rows\n",
        "display(df_rows.head(40))\n",
        "\n",
        "# Return small textual summary\n",
        "summary = {\n",
        "    \"pdf_path\": PDF_PATH,\n",
        "    \"num_pages\": len(df_pages),\n",
        "    \"num_table_cells\": int(df_rows.shape[0]),\n",
        "    \"num_rows_previewed\": int(min(40, df_rows.shape[0])),\n",
        "    \"outputs\": {\n",
        "        \"rows_csv\": \"pdf_table_rows.csv\",\n",
        "        \"pages_csv\": \"pdf_page_text.csv\"\n",
        "    }\n",
        "}\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "8Sm4qBVeajVe",
        "outputId": "cb45486f-be36-4952-9a44-460322fdaa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [page, table_idx, row_idx, col_idx, cell_text_verbatim, cell_text_normalized, row_join_verbatim, row_join_normalized, context_before]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32faaa20-8583-4bb2-b7bc-fe21241067e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page</th>\n",
              "      <th>table_idx</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>col_idx</th>\n",
              "      <th>cell_text_verbatim</th>\n",
              "      <th>cell_text_normalized</th>\n",
              "      <th>row_join_verbatim</th>\n",
              "      <th>row_join_normalized</th>\n",
              "      <th>context_before</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32faaa20-8583-4bb2-b7bc-fe21241067e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32faaa20-8583-4bb2-b7bc-fe21241067e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32faaa20-8583-4bb2-b7bc-fe21241067e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pdf_path': '7606_0_2025-06-18_13-35-36_Ar.pdf',\n",
              " 'num_pages': 18,\n",
              " 'num_table_cells': 0,\n",
              " 'num_rows_previewed': 0,\n",
              " 'outputs': {'rows_csv': 'pdf_table_rows.csv',\n",
              "  'pages_csv': 'pdf_page_text.csv'}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_rzkXrkdGpw",
        "outputId": "d335b719-8bc4-435a-b27b-464ce8c14c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust PDF table extractor with fallback (no caas_jupyter_tools required)\n",
        "# - Tries pdfplumber for structured tables.\n",
        "# - If none found, falls back to text-based \"row\" extraction from PyPDF:\n",
        "#     * Keep lines that look like table rows (>=2 numbers or many delimiters)\n",
        "#     * Split cells by multiple spaces / tabs / pipes\n",
        "#     * Preserve verbatim Arabic, plus a digit-normalized version\n",
        "# - Saves:\n",
        "#    /mnt/data/pdf_table_rows.csv         (structured if possible, else fallback rows)\n",
        "#    /mnt/data/pdf_table_rows_fallback.csv (always saved for debugging)\n",
        "#    /mnt/data/pdf_page_text.csv\n",
        "#\n",
        "# Notes:\n",
        "# - No dependency on caas_jupyter_tools.\n",
        "# - Should work even if pdfplumber is missing.\n",
        "# - Designed for Arabic/English mixed PDFs with numeric tables.\n",
        "#\n",
        "import os, re, csv\n",
        "import pandas as pd\n",
        "\n",
        "PDF_PATH = \"7606_0_2025-06-18_13-35-36_Ar.pdf\"\n",
        "\n",
        "# Arabic-Indic → ASCII, also normalize separators (٬٫ → , .)\n",
        "TRANS = str.maketrans(\"٠١٢٣٤٥٦٧٨٩٬٫\", \"0123456789,.\")\n",
        "def normalize_nums(s: str) -> str:\n",
        "    return (s or \"\").translate(TRANS)\n",
        "\n",
        "def try_pdfplumber_tables(pdf_path):\n",
        "    try:\n",
        "        import pdfplumber\n",
        "    except Exception:\n",
        "        return [], []\n",
        "    rows = []\n",
        "    pages_meta = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for p_idx, page in enumerate(pdf.pages, start=1):\n",
        "            page_text = (page.extract_text() or \"\").strip()\n",
        "            page_text = re.sub(r\"\\s+\", \" \", page_text)\n",
        "            pages_meta.append({\"page\": p_idx, \"text\": page_text})\n",
        "            try:\n",
        "                # both heuristics: tables() and extract_tables()\n",
        "                tables = page.extract_tables() or []\n",
        "            except Exception:\n",
        "                tables = []\n",
        "            for t_idx, tbl in enumerate(tables):\n",
        "                for r_idx, row in enumerate(tbl):\n",
        "                    # Emit one record per ROW (row_join) and also per CELL for precision search\n",
        "                    row_verbatim = [(\"\" if c is None else str(c).strip()) for c in row]\n",
        "                    row_norm = [normalize_nums(x) for x in row_verbatim]\n",
        "                    # Row-level\n",
        "                    rows.append({\n",
        "                        \"page\": p_idx, \"table_idx\": t_idx, \"row_idx\": r_idx,\n",
        "                        \"col_idx\": -1,\n",
        "                        \"cell_text_verbatim\": \"\",\n",
        "                        \"cell_text_normalized\": \"\",\n",
        "                        \"row_join_verbatim\": \" | \".join(row_verbatim),\n",
        "                        \"row_join_normalized\": \" | \".join(row_norm),\n",
        "                        \"context_before\": page_text[:200]\n",
        "                    })\n",
        "                    # Cell-level\n",
        "                    for c_idx, cell in enumerate(row_verbatim):\n",
        "                        rows.append({\n",
        "                            \"page\": p_idx, \"table_idx\": t_idx, \"row_idx\": r_idx,\n",
        "                            \"col_idx\": c_idx,\n",
        "                            \"cell_text_verbatim\": cell,\n",
        "                            \"cell_text_normalized\": normalize_nums(cell),\n",
        "                            \"row_join_verbatim\": \" | \".join(row_verbatim),\n",
        "                            \"row_join_normalized\": \" | \".join(row_norm),\n",
        "                            \"context_before\": page_text[:200]\n",
        "                        })\n",
        "    return rows, pages_meta\n",
        "\n",
        "def extract_text_pages(pdf_path):\n",
        "    # Fallback: use PyPDF only for page text\n",
        "    try:\n",
        "        from pypdf import PdfReader\n",
        "    except Exception:\n",
        "        return []\n",
        "    reader = PdfReader(pdf_path)\n",
        "    pages = []\n",
        "    for p_idx, page in enumerate(reader.pages, start=1):\n",
        "        text = page.extract_text() or \"\"\n",
        "        text = re.sub(r\"\\r\", \"\\n\", text)\n",
        "        # collapse >2 spaces into a single space but preserve newlines\n",
        "        text = re.sub(r\"[ \\t\\f\\v]+\", \" \", text)\n",
        "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "        pages.append({\"page\": p_idx, \"text\": text.strip()})\n",
        "    return pages\n",
        "\n",
        "def looks_like_table_line(line: str) -> bool:\n",
        "    \"\"\"Heuristic: a line is 'tabular' if it contains >=2 numbers or many separators.\"\"\"\n",
        "    norm = normalize_nums(line)\n",
        "    num_count = len(re.findall(r\"\\d+(?:[.,]\\d+)?\", norm))\n",
        "    sep_count = len(re.findall(r\"[|·•\\-–—\\t]\", line)) + len(re.findall(r\"\\s{2,}\", line))\n",
        "    return (num_count >= 2) or (sep_count >= 2)\n",
        "\n",
        "def split_cells(line: str):\n",
        "    \"\"\"Split by strong delimiters first, then by 2+ spaces.\"\"\"\n",
        "    if \"|\" in line:\n",
        "        parts = [p.strip() for p in line.split(\"|\")]\n",
        "    else:\n",
        "        parts = re.split(r\"\\s{2,}|\\t\", line)\n",
        "        parts = [p.strip() for p in parts if p.strip()]\n",
        "    return parts if len(parts) >= 2 else [line.strip()]\n",
        "\n",
        "def build_fallback_rows(pages_meta):\n",
        "    rows = []\n",
        "    for page in pages_meta:\n",
        "        p = page[\"page\"]\n",
        "        text = page[\"text\"]\n",
        "        for block in text.split(\"\\n\\n\"):\n",
        "            lines = [l.strip() for l in block.split(\"\\n\") if l.strip()]\n",
        "            # If many lines in a block are 'tabular', treat block as a table\n",
        "            tab_lines = [l for l in lines if looks_like_table_line(l)]\n",
        "            if len(tab_lines) >= max(2, int(0.5 * len(lines))):\n",
        "                # Emit a table_idx counter per page\n",
        "                table_idx = hash((p, block[:30])) % (10**6)\n",
        "                for r_idx, ln in enumerate(tab_lines):\n",
        "                    cells = split_cells(ln)\n",
        "                    row_verbatim = \" | \".join(cells)\n",
        "                    row_norm = \" | \".join([normalize_nums(c) for c in cells])\n",
        "                    # Row-level\n",
        "                    rows.append({\n",
        "                        \"page\": p, \"table_idx\": table_idx, \"row_idx\": r_idx, \"col_idx\": -1,\n",
        "                        \"cell_text_verbatim\": \"\",\n",
        "                        \"cell_text_normalized\": \"\",\n",
        "                        \"row_join_verbatim\": row_verbatim,\n",
        "                        \"row_join_normalized\": row_norm,\n",
        "                        \"context_before\": text[:200].replace(\"\\n\", \" \")\n",
        "                    })\n",
        "                    # Cell-level\n",
        "                    for c_idx, cell in enumerate(cells):\n",
        "                        rows.append({\n",
        "                            \"page\": p, \"table_idx\": table_idx, \"row_idx\": r_idx, \"col_idx\": c_idx,\n",
        "                            \"cell_text_verbatim\": cell,\n",
        "                            \"cell_text_normalized\": normalize_nums(cell),\n",
        "                            \"row_join_verbatim\": row_verbatim,\n",
        "                            \"row_join_normalized\": row_norm,\n",
        "                            \"context_before\": text[:200].replace(\"\\n\", \" \")\n",
        "                        })\n",
        "    return rows\n",
        "\n",
        "# 1) Try structured extraction\n",
        "rows_struct, pages_meta = try_pdfplumber_tables(PDF_PATH)\n",
        "\n",
        "# 2) Always get page texts\n",
        "if not pages_meta:\n",
        "    pages_meta = extract_text_pages(PDF_PATH)\n",
        "\n",
        "# Save page texts\n",
        "pd.DataFrame(pages_meta).to_csv(\"pdf_page_text.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 3) Fallback from page text if no structured tables found\n",
        "rows_fallback = build_fallback_rows(pages_meta)\n",
        "\n",
        "# Prefer structured rows if any; else use fallback\n",
        "rows_final = rows_struct if rows_struct else rows_fallback\n",
        "\n",
        "# Persist both for debugging\n",
        "pd.DataFrame(rows_fallback).to_csv(\"pdf_table_rows_fallback.csv\", index=False, encoding=\"utf-8\")\n",
        "pd.DataFrame(rows_final).to_csv(\"pdf_table_rows.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "summary = {\n",
        "    \"pages\": len(pages_meta),\n",
        "    \"rows_structured\": len(rows_struct),\n",
        "    \"rows_fallback\": len(rows_fallback),\n",
        "    \"rows_final\": len(rows_final),\n",
        "    \"outputs\": {\n",
        "        \"rows_csv\": \"pdf_table_rows.csv\",\n",
        "        \"rows_fallback_csv\": \"pdf_table_rows_fallback.csv\",\n",
        "        \"pages_csv\": \"pdf_page_text.csv\",\n",
        "    }\n",
        "}\n",
        "summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V4_4Ls6aj_0",
        "outputId": "115db1ad-7d9a-41ef-cdcc-1a111779b821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pages': 18,\n",
              " 'rows_structured': 103,\n",
              " 'rows_fallback': 0,\n",
              " 'rows_final': 103,\n",
              " 'outputs': {'rows_csv': 'pdf_table_rows.csv',\n",
              "  'rows_fallback_csv': 'pdf_table_rows_fallback.csv',\n",
              "  'pages_csv': 'pdf_page_text.csv'}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}