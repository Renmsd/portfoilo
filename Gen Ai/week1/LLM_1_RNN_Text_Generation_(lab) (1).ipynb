{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3632443",
      "metadata": {
        "id": "a3632443"
      },
      "source": [
        "<img src=\"https://s3.amazonaws.com/weclouddata/images/logos/wcd_logo_new_2.png\" width=\"10%\">\n",
        "<h1><center>RNN Exercise</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7264da08",
      "metadata": {
        "id": "7264da08"
      },
      "source": [
        "In this exercise, we will build a Recurrent Neural Network (RNN) using PyTorch to generate text in the style of Shakespeare."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9488b2",
      "metadata": {
        "id": "2d9488b2"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "514a00e4",
      "metadata": {
        "id": "514a00e4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d5eb00",
      "metadata": {
        "id": "b0d5eb00"
      },
      "source": [
        "## Prepare the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "456a8e2c",
      "metadata": {
        "id": "456a8e2c"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"In the burgeoning cityscape, where skyscrapers pierce the clouds and the buzz of urban life is never-ending, the stories of a million souls intertwine, each one a thread in the tapestry of a metropolis.\",\n",
        "    \"Beneath the canopy of the ancient forest, where light filters through leaves and the air is alive with the whispers of nature, the old secrets of the earth are guarded by the timeless sentinels of the woods.\",\n",
        "    \"On the tempestuous seas, where the waves are mountains and the wind roars with the fury of the gods, mariners navigate by starlight, their hearts as boundless as the ocean they traverse.\",\n",
        "    \"In the silent expanse of the desert, where sand dunes rise like waves in a frozen sea and the sun reigns unchallenged, the beauty of the barren is a testament to the extremes of our world.\",\n",
        "    \"Above the peaks of the highest mountains, where the air is thin and the edge of the sky seems a hand's breadth away, the horizon stretches into infinity, a reminder of the vastness of our planet.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b563e535",
      "metadata": {
        "id": "b563e535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324eec97-a6ce-4ec1-8e6a-818b4e934cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'n', ' ', 't', 'h', 'e', ' ', 'b', 'u', 'r', 'g', 'e', 'o', 'n', 'i', 'n', 'g', ' ', 'c', 'i', 't', 'y', 's', 'c', 'a', 'p', 'e', ',', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 's', 'k', 'y', 's', 'c', 'r', 'a', 'p', 'e', 'r', 's', ' ', 'p', 'i', 'e', 'r', 'c', 'e', ' ', 't', 'h', 'e', ' ', 'c', 'l', 'o', 'u', 'd', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'b', 'u', 'z', 'z', ' ', 'o', 'f', ' ', 'u', 'r', 'b', 'a', 'n', ' ', 'l', 'i', 'f', 'e', ' ', 'i', 's', ' ', 'n', 'e', 'v', 'e', 'r', '-', 'e', 'n', 'd', 'i', 'n', 'g', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'o', 'r', 'i', 'e', 's', ' ', 'o', 'f', ' ', 'a', ' ', 'm', 'i', 'l', 'l', 'i', 'o', 'n', ' ', 's', 'o', 'u', 'l', 's', ' ', 'i', 'n', 't', 'e', 'r', 't', 'w', 'i', 'n', 'e', ',', ' ', 'e', 'a', 'c', 'h', ' ', 'o', 'n', 'e', ' ', 'a', ' ', 't', 'h', 'r', 'e', 'a', 'd', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 't', 'a', 'p', 'e', 's', 't', 'r', 'y', ' ', 'o', 'f', ' ', 'a', ' ', 'm', 'e', 't', 'r', 'o', 'p', 'o', 'l', 'i', 's', '.', 'B', 'e', 'n', 'e', 'a', 't', 'h', ' ', 't', 'h', 'e', ' ', 'c', 'a', 'n', 'o', 'p', 'y', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'a', 'n', 'c', 'i', 'e', 'n', 't', ' ', 'f', 'o', 'r', 'e', 's', 't', ',', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 'l', 'i', 'g', 'h', 't', ' ', 'f', 'i', 'l', 't', 'e', 'r', 's', ' ', 't', 'h', 'r', 'o', 'u', 'g', 'h', ' ', 'l', 'e', 'a', 'v', 'e', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'a', 'i', 'r', ' ', 'i', 's', ' ', 'a', 'l', 'i', 'v', 'e', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'w', 'h', 'i', 's', 'p', 'e', 'r', 's', ' ', 'o', 'f', ' ', 'n', 'a', 't', 'u', 'r', 'e', ',', ' ', 't', 'h', 'e', ' ', 'o', 'l', 'd', ' ', 's', 'e', 'c', 'r', 'e', 't', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'e', 'a', 'r', 't', 'h', ' ', 'a', 'r', 'e', ' ', 'g', 'u', 'a', 'r', 'd', 'e', 'd', ' ', 'b', 'y', ' ', 't', 'h', 'e', ' ', 't', 'i', 'm', 'e', 'l', 'e', 's', 's', ' ', 's', 'e', 'n', 't', 'i', 'n', 'e', 'l', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'o', 'd', 's', '.', 'O', 'n', ' ', 't', 'h', 'e', ' ', 't', 'e', 'm', 'p', 'e', 's', 't', 'u', 'o', 'u', 's', ' ', 's', 'e', 'a', 's', ',', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 't', 'h', 'e', ' ', 'w', 'a', 'v', 'e', 's', ' ', 'a', 'r', 'e', ' ', 'm', 'o', 'u', 'n', 't', 'a', 'i', 'n', 's', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'w', 'i', 'n', 'd', ' ', 'r', 'o', 'a', 'r', 's', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'f', 'u', 'r', 'y', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'g', 'o', 'd', 's', ',', ' ', 'm', 'a', 'r', 'i', 'n', 'e', 'r', 's', ' ', 'n', 'a', 'v', 'i', 'g', 'a', 't', 'e', ' ', 'b', 'y', ' ', 's', 't', 'a', 'r', 'l', 'i', 'g', 'h', 't', ',', ' ', 't', 'h', 'e', 'i', 'r', ' ', 'h', 'e', 'a', 'r', 't', 's', ' ', 'a', 's', ' ', 'b', 'o', 'u', 'n', 'd', 'l', 'e', 's', 's', ' ', 'a', 's', ' ', 't', 'h', 'e', ' ', 'o', 'c', 'e', 'a', 'n', ' ', 't', 'h', 'e', 'y', ' ', 't', 'r', 'a', 'v', 'e', 'r', 's', 'e', '.', 'I', 'n', ' ', 't', 'h', 'e', ' ', 's', 'i', 'l', 'e', 'n', 't', ' ', 'e', 'x', 'p', 'a', 'n', 's', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'd', 'e', 's', 'e', 'r', 't', ',', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 's', 'a', 'n', 'd', ' ', 'd', 'u', 'n', 'e', 's', ' ', 'r', 'i', 's', 'e', ' ', 'l', 'i', 'k', 'e', ' ', 'w', 'a', 'v', 'e', 's', ' ', 'i', 'n', ' ', 'a', ' ', 'f', 'r', 'o', 'z', 'e', 'n', ' ', 's', 'e', 'a', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 's', 'u', 'n', ' ', 'r', 'e', 'i', 'g', 'n', 's', ' ', 'u', 'n', 'c', 'h', 'a', 'l', 'l', 'e', 'n', 'g', 'e', 'd', ',', ' ', 't', 'h', 'e', ' ', 'b', 'e', 'a', 'u', 't', 'y', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'b', 'a', 'r', 'r', 'e', 'n', ' ', 'i', 's', ' ', 'a', ' ', 't', 'e', 's', 't', 'a', 'm', 'e', 'n', 't', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'e', 'x', 't', 'r', 'e', 'm', 'e', 's', ' ', 'o', 'f', ' ', 'o', 'u', 'r', ' ', 'w', 'o', 'r', 'l', 'd', '.', 'A', 'b', 'o', 'v', 'e', ' ', 't', 'h', 'e', ' ', 'p', 'e', 'a', 'k', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'h', 'i', 'g', 'h', 'e', 's', 't', ' ', 'm', 'o', 'u', 'n', 't', 'a', 'i', 'n', 's', ',', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 't', 'h', 'e', ' ', 'a', 'i', 'r', ' ', 'i', 's', ' ', 't', 'h', 'i', 'n', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'e', 'd', 'g', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 'k', 'y', ' ', 's', 'e', 'e', 'm', 's', ' ', 'a', ' ', 'h', 'a', 'n', 'd', \"'\", 's', ' ', 'b', 'r', 'e', 'a', 'd', 't', 'h', ' ', 'a', 'w', 'a', 'y', ',', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'r', 'i', 'z', 'o', 'n', ' ', 's', 't', 'r', 'e', 't', 'c', 'h', 'e', 's', ' ', 'i', 'n', 't', 'o', ' ', 'i', 'n', 'f', 'i', 'n', 'i', 't', 'y', ',', ' ', 'a', ' ', 'r', 'e', 'm', 'i', 'n', 'd', 'e', 'r', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'v', 'a', 's', 't', 'n', 'e', 's', 's', ' ', 'o', 'f', ' ', 'o', 'u', 'r', ' ', 'p', 'l', 'a', 'n', 'e', 't', '.', '<eos>', '<pad>', '<bos>']\n",
            " unique characters: \n",
            " {'i', 'h', 'd', 'p', '<bos>', 'v', 'n', 'e', '<pad>', 'c', 'k', 'A', 'r', 't', ' ', 'u', ',', 'x', '-', 'g', 'b', 'f', 'I', 'z', 'l', 'y', '<eos>', 'o', 'm', '.', 'w', \"'\", 'B', 's', 'a', 'O'}\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            " dictionary int2char: \n",
            " {0: 'i', 1: 'h', 2: 'd', 3: 'p', 4: '<bos>', 5: 'v', 6: 'n', 7: 'e', 8: '<pad>', 9: 'c', 10: 'k', 11: 'A', 12: 'r', 13: 't', 14: ' ', 15: 'u', 16: ',', 17: 'x', 18: '-', 19: 'g', 20: 'b', 21: 'f', 22: 'I', 23: 'z', 24: 'l', 25: 'y', 26: '<eos>', 27: 'o', 28: 'm', 29: '.', 30: 'w', 31: \"'\", 32: 'B', 33: 's', 34: 'a', 35: 'O'}\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            " dictionary char2int: \n",
            " {'i': 0, 'h': 1, 'd': 2, 'p': 3, '<bos>': 4, 'v': 5, 'n': 6, 'e': 7, '<pad>': 8, 'c': 9, 'k': 10, 'A': 11, 'r': 12, 't': 13, ' ': 14, 'u': 15, ',': 16, 'x': 17, '-': 18, 'g': 19, 'b': 20, 'f': 21, 'I': 22, 'z': 23, 'l': 24, 'y': 25, '<eos>': 26, 'o': 27, 'm': 28, '.': 29, 'w': 30, \"'\": 31, 'B': 32, 's': 33, 'a': 34, 'O': 35}\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Create the vocabulary(char list), don't forget <eos>, <pad>, <bos>\n",
        "# Create a mapping from unique characters to indices(char2int) and integers(index) to the characters (int2char)\n",
        "# your code here\n",
        "vocab = set(list(''.join(texts)) + ['<eos>', '<pad>', '<bos>'])\n",
        "print(list(''.join(texts)) + ['<eos>', '<pad>', '<bos>'])\n",
        "print(f' unique characters: \\n {vocab}')\n",
        "print('-'*140)\n",
        "int2char =dict(enumerate(vocab))\n",
        "print(f'\\n dictionary int2char: \\n {int2char}')\n",
        "print('-'*140)\n",
        "char2int = {char: index for index, char in int2char.items()}\n",
        "print(f'\\n dictionary char2int: \\n {char2int}')\n",
        "print('-'*140)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83017c5f",
      "metadata": {
        "id": "83017c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a07ccce-eceb-450d-f9e2-8b4cbd70be34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest string has 207 characters\n"
          ]
        }
      ],
      "source": [
        "maxlen = len(max(texts, key=len))\n",
        "print(\"The longest string has {} characters\".format(maxlen))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08150ee",
      "metadata": {
        "id": "c08150ee"
      },
      "source": [
        "## Create Input and Target Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "39e3d2c1",
      "metadata": {
        "id": "39e3d2c1"
      },
      "outputs": [],
      "source": [
        "# Vocabulary size\n",
        "vocab_size = len(char2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85571738",
      "metadata": {
        "id": "85571738"
      },
      "outputs": [],
      "source": [
        "# Special token indices\n",
        "bos_idx = char2int['<bos>']\n",
        "eos_idx = char2int['<eos>']\n",
        "pad_idx = char2int['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e1db243b",
      "metadata": {
        "id": "e1db243b"
      },
      "outputs": [],
      "source": [
        "# Creating lists that will hold our input and target sequences\n",
        "# Note: In This Exercise, let's make train_X and train_Y are lists of **integer indices**, **not** one-hot encoded vectors.\n",
        "train_X = []\n",
        "train_Y = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ac8fdcca",
      "metadata": {
        "id": "ac8fdcca"
      },
      "outputs": [],
      "source": [
        "# Creating lists that will hold our input and target sequences\n",
        "# Note: In This Exercise, let's make train_X and train_Y are lists of **integer indices**, **not** one-hot encoded vectors.\n",
        "train_X = []\n",
        "train_Y = []\n",
        "\n",
        "# Iterate the texts and slice the texts into sequences of 'maxlen' characters\n",
        "# finish the forloop below following the instructions\n",
        "for text in texts:\n",
        "\n",
        "    # Convert text to list of integer indices and prepend with <bos> and append <eos>\n",
        "    # Your code here\n",
        "    indexed_text = [bos_idx] + [char2int[char] for char in text] + [eos_idx]\n",
        "\n",
        "    # Extract the target sequence (shifted one character to the right) and append <eos>\n",
        "    # Your code here\n",
        "    target_text = indexed_text[1:] + [eos_idx]\n",
        "\n",
        "    # Check for shorter sequences and pad them\n",
        "    # The length should be at least maxlen+2\n",
        "    # Your code here\n",
        "    padding_length = maxlen + 2 - len(indexed_text)\n",
        "    if padding_length > 0:\n",
        "        indexed_text += [char2int['<pad>']] * padding_length\n",
        "        target_text += [char2int['<pad>']] * padding_length\n",
        "\n",
        "\n",
        "    # Append the extracted sequences to the training lists\n",
        "    # Your code here\n",
        "    train_X.append(indexed_text)\n",
        "    train_Y.append(target_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28d3322",
      "metadata": {
        "scrolled": true,
        "id": "c28d3322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e3863b-6f34-4a0a-9694-f35d2a857ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> -> I\n",
            "I -> n\n",
            "n ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> e\n",
            "e ->  \n",
            "  -> b\n",
            "b -> u\n",
            "u -> r\n",
            "r -> g\n",
            "g -> e\n",
            "e -> o\n",
            "o -> n\n",
            "n -> i\n",
            "i -> n\n",
            "n -> g\n",
            "g ->  \n",
            "  -> c\n",
            "c -> i\n",
            "i -> t\n",
            "t -> y\n",
            "y -> s\n",
            "s -> c\n",
            "c -> a\n",
            "a -> p\n",
            "p -> e\n",
            "e -> ,\n",
            ", ->  \n",
            "  -> w\n",
            "w -> h\n",
            "h -> e\n",
            "e -> r\n",
            "r -> e\n",
            "e ->  \n",
            "  -> s\n",
            "s -> k\n",
            "k -> y\n",
            "y -> s\n",
            "s -> c\n",
            "c -> r\n",
            "r -> a\n",
            "a -> p\n",
            "p -> e\n",
            "e -> r\n",
            "r -> s\n",
            "s ->  \n",
            "  -> p\n",
            "p -> i\n",
            "i -> e\n",
            "e -> r\n",
            "r -> c\n",
            "c -> e\n",
            "e ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> e\n",
            "e ->  \n",
            "  -> c\n",
            "c -> l\n",
            "l -> o\n",
            "o -> u\n",
            "u -> d\n",
            "d -> s\n",
            "s ->  \n",
            "  -> a\n",
            "a -> n\n",
            "n -> d\n",
            "d ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> e\n",
            "e ->  \n",
            "  -> b\n",
            "b -> u\n",
            "u -> z\n",
            "z -> z\n",
            "z ->  \n",
            "  -> o\n",
            "o -> f\n",
            "f ->  \n",
            "  -> u\n",
            "u -> r\n",
            "r -> b\n",
            "b -> a\n",
            "a -> n\n",
            "n ->  \n",
            "  -> l\n",
            "l -> i\n",
            "i -> f\n",
            "f -> e\n",
            "e ->  \n",
            "  -> i\n",
            "i -> s\n",
            "s ->  \n",
            "  -> n\n",
            "n -> e\n",
            "e -> v\n",
            "v -> e\n",
            "e -> r\n",
            "r -> -\n",
            "- -> e\n",
            "e -> n\n",
            "n -> d\n",
            "d -> i\n",
            "i -> n\n",
            "n -> g\n",
            "g -> ,\n",
            ", ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> e\n",
            "e ->  \n",
            "  -> s\n",
            "s -> t\n",
            "t -> o\n",
            "o -> r\n",
            "r -> i\n",
            "i -> e\n",
            "e -> s\n",
            "s ->  \n",
            "  -> o\n",
            "o -> f\n",
            "f ->  \n",
            "  -> a\n",
            "a ->  \n",
            "  -> m\n",
            "m -> i\n",
            "i -> l\n",
            "l -> l\n",
            "l -> i\n",
            "i -> o\n",
            "o -> n\n",
            "n ->  \n",
            "  -> s\n",
            "s -> o\n",
            "o -> u\n",
            "u -> l\n",
            "l -> s\n",
            "s ->  \n",
            "  -> i\n",
            "i -> n\n",
            "n -> t\n",
            "t -> e\n",
            "e -> r\n",
            "r -> t\n",
            "t -> w\n",
            "w -> i\n",
            "i -> n\n",
            "n -> e\n",
            "e -> ,\n",
            ", ->  \n",
            "  -> e\n",
            "e -> a\n",
            "a -> c\n",
            "c -> h\n",
            "h ->  \n",
            "  -> o\n",
            "o -> n\n",
            "n -> e\n",
            "e ->  \n",
            "  -> a\n",
            "a ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> r\n",
            "r -> e\n",
            "e -> a\n",
            "a -> d\n",
            "d ->  \n",
            "  -> i\n",
            "i -> n\n",
            "n ->  \n",
            "  -> t\n",
            "t -> h\n",
            "h -> e\n",
            "e ->  \n",
            "  -> t\n",
            "t -> a\n",
            "a -> p\n",
            "p -> e\n",
            "e -> s\n",
            "s -> t\n",
            "t -> r\n",
            "r -> y\n",
            "y ->  \n",
            "  -> o\n",
            "o -> f\n",
            "f ->  \n",
            "  -> a\n",
            "a ->  \n",
            "  -> m\n",
            "m -> e\n",
            "e -> t\n",
            "t -> r\n",
            "r -> o\n",
            "o -> p\n",
            "p -> o\n",
            "o -> l\n",
            "l -> i\n",
            "i -> s\n",
            "s -> .\n",
            ". -> <eos>\n",
            "<eos> -> <eos>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n"
          ]
        }
      ],
      "source": [
        "# Quick check\n",
        "for x,y in zip(train_X[0], train_Y[0]):\n",
        "    print(int2char[x], '->', int2char[y])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f51e55",
      "metadata": {
        "id": "c7f51e55"
      },
      "source": [
        "## Define the RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0d86e20e",
      "metadata": {
        "id": "0d86e20e"
      },
      "outputs": [],
      "source": [
        "# Implement the RNN model follow the instructions and function doc\n",
        "# Let's use the nn.RNN() here\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A class for creating an RNN model which can process sequences of data by using an embedding layer followed by recurrent layers and a final fully connected layer to produce outputs corresponding to the vocabulary size.\n",
        "\n",
        "    Attributes:\n",
        "        embedding (nn.Embedding): An embedding layer that converts input indices into dense vectors of a specified size.\n",
        "        rnn (nn.RNN): The RNN layers that sequentially process the data, maintaining a hidden state through the sequence.\n",
        "        fc (nn.Linear): A linear layer that projects the RNN layer outputs to a space with dimensionality equal to the size of the vocabulary.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, drop_prob=0):\n",
        "        \"\"\"\n",
        "        Initialize the RNNModel with the given parameters.\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): The number of items in the vocabulary.\n",
        "            embedding_dim (int): The size of the embedding vector.\n",
        "            hidden_dim (int): The number of features in the hidden state of the RNN.\n",
        "            output_dim (int): The size of the output vector (should be equal to the vocab size).\n",
        "            n_layers (int): The number of stacked RNN layers.\n",
        "            drop_prob (float): The dropout rate.\n",
        "            \"\"\"\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        # Create an embedding layer (nn.Embedding) with vocab_size and embedding_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Create an RNN layer (nn.RNN) with embedding_dim, hidden_dim, n_layers, and dropout, uses batch_first=True to accept input and output tensors with (batch, seq, feature).\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        # Create a fully connected layer (nn.Linear) with hidden_dim and output_dim\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Forward pass of the RNN model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): A batch of input sequences represented as token indices.\n",
        "            hidden (Tensor): The initial hidden state of the RNN.\n",
        "\n",
        "        Returns:\n",
        "            Tensor, Tensor: The output logits for each sequence at each timestep, and the final hidden state.\n",
        "        \"\"\"\n",
        "        # Apply the embedding layer on x\n",
        "        embedded = self.embedding(x)\n",
        "        # Pass the embedded input and hidden state through the RNN layer\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        # Prepare the output from RNN for the fully connected layer. Hint: use contiguous().view()\n",
        "        output = output.contiguous().view(-1, self.hidden_dim)\n",
        "        # Apply the fully connected layer on the RNN output\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"\n",
        "        Initializes the hidden state to zero for the start of a new batch processing.\n",
        "\n",
        "        Args:\n",
        "            batch_size (int): The size of the batch for which to create the initial hidden state.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: A new tensor of zeros for the initial hidden state of the RNN with the appropriate dimensions.\n",
        "        \"\"\"\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f921f57",
      "metadata": {
        "id": "6f921f57"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ed89e608",
      "metadata": {
        "id": "ed89e608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11c9831-825b-4e32-a520-8224b35ff91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU/CUDA is available and set the device accordingly\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0f9995b1",
      "metadata": {
        "scrolled": true,
        "id": "0f9995b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb50bd46-ef5b-4107-bd51-c6d47c7d020b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.6117\n",
            "Epoch [20/100], Loss: 0.0883\n",
            "Epoch [30/100], Loss: 0.0190\n",
            "Epoch [40/100], Loss: 0.0117\n",
            "Epoch [50/100], Loss: 0.0091\n",
            "Epoch [60/100], Loss: 0.0076\n",
            "Epoch [70/100], Loss: 0.0066\n",
            "Epoch [80/100], Loss: 0.0059\n",
            "Epoch [90/100], Loss: 0.0054\n",
            "Epoch [100/100], Loss: 0.0050\n"
          ]
        }
      ],
      "source": [
        "# TODO: Set the hyperparameters\n",
        "# Define the size of the vocabulary (number of unique characters in the dataset)\n",
        "# Define the dimension size for the embeddings\n",
        "# Define the number of features in the hidden state of the RNN\n",
        "# The output dimension is the size of the vocabulary\n",
        "# Define the number of RNN layers\n",
        "# Your Code Here\n",
        "embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "output_dim = vocab_size\n",
        "\n",
        "\n",
        "# Initialize the RNN model using the hyperparameters\n",
        "# move the model to device\n",
        "# Your Code Here\n",
        "model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers).to(device)\n",
        "\n",
        "\n",
        "# Initialize the loss function as CrossEntropyLoss\n",
        "# Initialize the optimizer as Adam, with learning rate of 0.001\n",
        "# Your Code Here\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Set the number of epochs for training\n",
        "# Your Code Here\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "# Start the training loop\n",
        "# Iterate over each epoch\n",
        "# In each epoch, you need to:\n",
        "# 1.Initialize the hidden layer, the batch size is 1\n",
        "# 2.Iterate over each sample in the dataset\n",
        "# 3.Calculate and print the loss every 10 epoch\n",
        "# And in each iteration, you need to:\n",
        "# 1.Convert the current input and target sequences to tensors and add a batch dimension, move the tensor to device.\n",
        "# Hint: you need to use unsqueeze() to deal with the dimension\n",
        "# 2.Zero the gradients before running the forward pass.\n",
        "# 3.Perform the forward pass through the model\n",
        "# 4.Compute the loss between the outputs and the targets, you need to use view() to adjust the dimension\n",
        "# 5.Perform the backward pass to compute the gradients\n",
        "# 6.Update the parameters based on the gradients\n",
        "# 7.Detach hidden state to prevent backpropagating through the entire history\n",
        "# Your Code Here\n",
        "for epoch in range(epochs):\n",
        "    hidden = model.init_hidden(1)  # Batch size is 1\n",
        "\n",
        "    for i in range(len(train_X)):\n",
        "        # Convert input and target sequences to tensors and move to device\n",
        "        inputs = torch.tensor(train_X[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        targets = torch.tensor(train_Y[i], dtype=torch.long).to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output, hidden = model(inputs, hidden)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Detach hidden state\n",
        "        hidden = hidden.detach()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9134bf08",
      "metadata": {
        "id": "9134bf08"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ada997f",
      "metadata": {
        "id": "1ada997f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ac221d-a51f-4502-8fe5-628b2f59e05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the tempestuous seas, where the waves are mountains and the wind roars with the fury of the gods, mariners navigate by starlight, their hearts as boundless as the ocean they traverse.<eos>\n"
          ]
        }
      ],
      "source": [
        "# Write a generate text function, which can use the model to generate a string with the giving start_string\n",
        "\n",
        "def generate_text(start_string, model, length=1000, device='cpu'):\n",
        "\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Convert the start string to a list of integers (character indices).\n",
        "    input_eval = [char2int[s] for s in start_string]\n",
        "\n",
        "    # Convert this list to a PyTorch tensor and add a batch dimension.\n",
        "    input_eval = torch.tensor(input_eval, device=device).unsqueeze(0)\n",
        "\n",
        "    # Initialize the hidden state of the model.\n",
        "    hidden = model.init_hidden(1).to(device)\n",
        "\n",
        "    generated = start_string\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "\n",
        "            # Pass the input and hidden state to the model to obtain the next output and new hidden state.\n",
        "            output, hidden = model(input_eval, hidden)\n",
        "\n",
        "            # Only take the last character's logits from the output to make predictions.\n",
        "            last_char_logits = output[-1]\n",
        "\n",
        "            # Convert the logits to probabilities for sampling.\n",
        "            probabilities = torch.nn.functional.softmax(last_char_logits, dim=-1)\n",
        "\n",
        "            # Randomly select the next character based on the probability distribution.\n",
        "            predicted_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "\n",
        "            # Append the predicted character to the generated text.\n",
        "            generated += int2char[predicted_id]\n",
        "\n",
        "            # Prepare the input for the next prediction step.\n",
        "            input_eval = torch.tensor([[predicted_id]], device=device)\n",
        "\n",
        "            # If the model predicts the end of sentence token, stop the generation.\n",
        "            if int2char[predicted_id] == '<eos>':\n",
        "                return generated\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Generate and print the text\n",
        "print(generate_text(\"On \", model, 300, device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a864ab4a",
      "metadata": {
        "id": "a864ab4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87410175",
      "metadata": {
        "id": "87410175"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}